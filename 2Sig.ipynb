{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "with pd.HDFStore(\"C:\\\\Users\\\\4126694\\\\2sig-kaggle\\\\input\\\\train.h5\", \"r\") as train:\n",
    "    # Note that the \"train\" dataframe is the only dataframe in the file\n",
    "    df = train.get(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means = df.drop(['y', 'timestamp'], axis=1).groupby('id').agg([np.std]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = df[\"id\"].unique()\n",
    "ids_in = {}\n",
    "ts_lens ={}\n",
    "for x in ids:\n",
    "    time = df[df[\"id\"] == x].timestamp\n",
    "    if time.min() > 100 and time.max() < 1812:\n",
    "        ids_in[x] = (time.min(), time.max())\n",
    "        ts_lens[x] = time.max()-time.max()\n",
    "\n",
    "for k, v in sorted(ids_in.items())[:10]:\n",
    "    print(\"id {} in [{},{}]\".format(k,v[0],v[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instrument = 52\n",
    "dfi = df[df[\"id\"] == instrument]\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(dfi[\"timestamp\"], dfi[\"y\"], linestyle=\"none\", marker=\".\")\n",
    "plt.xlabel('timestamp')\n",
    "plt.ylabel('returns')\n",
    "_ = plt.title('returns for id {}'.format(instrument))\n",
    "\n",
    "pd.set_option('mode.chained_assignment',None)\n",
    "dfi.loc[:,\"cumprod\"] = (1+dfi[\"y\"]).cumprod()\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(dfi[\"timestamp\"], dfi[\"cumprod\"], linestyle=\"none\", marker=\".\")\n",
    "plt.xlabel('timestamp')\n",
    "plt.ylabel('value')\n",
    "_ = plt.title('compound returns for id {}'.format(instrument))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = [x for x in dfi.columns.values if x not in [\"id\", \"timestamp\",\"y\",\"cumprod\"]]\n",
    "l = len(cols)\n",
    "f, ax = plt.subplots(int(l/3) + (1 if l%3 > 0 else 0), 3, figsize=(12,int(1.5*l)))\n",
    "cnt = 0\n",
    "for col in cols:\n",
    "    fig = ax[int(cnt/3),cnt%3]\n",
    "    fig.plot(dfi[\"timestamp\"], dfi[col], linestyle=\"none\", marker=\".\")\n",
    "    fig.set_title(\"{} for id {}\".format(col,instrument))\n",
    "    fig.set_xlim([0,2000])\n",
    "    fig.axvline(x=ids_in[instrument][0],color=\"r\",linewidth=1)\n",
    "    fig.axvline(x=ids_in[instrument][1],color=\"r\",linewidth=1)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = [x for x in dfi.columns.values if x not in [\"id\", \"timestamp\",\"y\",\"cumprod\"]]\n",
    "l = len(cols)\n",
    "dfj = dfi.fillna(0)\n",
    "target = dfj.pop('y')\n",
    "ts = dfj.pop('timestamp')\n",
    "dfj = dfi.drop([\"id\",\"y\",\"cumprod\"],axis=1)\n",
    "dfj=dfj.fillna(0)\n",
    "features = dfj.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(data, test_size=0.1):  \n",
    "    \"\"\"\n",
    "    This just splits data to training and testing parts\n",
    "    \"\"\"   \n",
    "    df = pd.DataFrame(data)    \n",
    "    ntrn = round(len(df) * (1 - test_size))\n",
    "    ntrn = int(ntrn)\n",
    "    tt = df.iloc[0:ntrn]\n",
    "    vv = df.iloc[ntrn:]\n",
    "    \n",
    "    train = np.array(tt)\n",
    "    val = np.array(vv)\n",
    "\n",
    "\n",
    "    return (train, val)\n",
    "\n",
    "(xtrain, xval) = train_test_split(features)\n",
    "(ytrain, yval) = train_test_split(target) \n",
    "(tstrain, tsval) = train_test_split(ts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "nest = 300\n",
    "md = 10\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "#regr_1 = DecisionTreeRegressor(max_depth=4)\n",
    "#regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=md), n_estimators=nest, random_state=rng)\n",
    "#regr_3 = GradientBoostingRegressor(n_estimators=nest, learning_rate=0.1, max_depth=md, random_state=rng, loss='ls')\n",
    "regr_4 = MultiOutputRegressor(RandomForestRegressor(n_estimators=nest, max_depth=md, random_state=0))\n",
    "regr_5 = RandomForestRegressor(n_estimators=nest, max_depth=md, random_state=rng)\n",
    "\n",
    "#regr_1.fit(features, target)\n",
    "#regr_2.fit(xtrain, ytrain)\n",
    "#regr_3.fit(xtrain, ytrain)\n",
    "regr_4.fit(xtrain, ytrain)\n",
    "regr_5.fit(xtrain, ytrain)\n",
    "\n",
    "#y_1 = regr_1.predict(features)\n",
    "#y_2 = regr_2.predict(xval)\n",
    "#y_3 = regr_3.predict(xval)\n",
    "y_4 = regr_4.predict(xval)\n",
    "y_5 = regr_5.predict(xval)\n",
    "\n",
    "#mse2 = mean_squared_error(yval, y_2)\n",
    "#mse3 = mean_squared_error(yval, y_3)\n",
    "mse4 = mean_squared_error(yval, y_4)\n",
    "mse5 = mean_squared_error(yval, y_5)\n",
    "\n",
    "print(\"MSE4: %.6f  MSE5: %.6f\" % (mse4,mse5))\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(ts, target,c=\"k\",label=\"training samples\")\n",
    "plt.plot(tsval, y_4, c=\"g\", label=\"ADABoost500\", linewidth=2)\n",
    "plt.plot(tsval, y_5, c=\"r\", label=\"GradBoost500\", linewidth=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_importance = regr_2.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "#plt.subplot(1, 2, 2)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, dfj.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute test set deviance\n",
    "nest = 300\n",
    "test_score = np.zeros((nest,), dtype=np.float64)\n",
    "\n",
    "for i, y_pred in enumerate(regr_3.staged_predict(xval)):\n",
    "    test_score[i] = regr_3.loss_(yval, y_3)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.title('Deviance')\n",
    "plt.plot(np.arange(nest) + 1, regr_3.train_score_, 'b-',\n",
    "         label='Training Set Deviance')\n",
    "plt.plot(np.arange(nest) + 1, test_score, 'r-',\n",
    "         label='Test Set Deviance')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Boosting Iterations')\n",
    "plt.ylabel('Deviance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from pandas.tseries.offsets import *\n",
    "from keras import callbacks\n",
    "\n",
    "remote = callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=l+1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))  \n",
    "Activation('linear')\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(xtrain, ytrain, batch_size=256, nb_epoch=20, validation_split=0.2, callbacks=[remote])  \n",
    "\n",
    "\n",
    "predicted = model.predict(xval) \n",
    "dataf =  pd.DataFrame(predicted[:1200])\n",
    "dataf.columns = [\"predict\"]\n",
    "dataf[\"input\"] = yval[:1200]\n",
    "dataf.plot(figsize=(15, 5))\n",
    "\n",
    "#score = model.evaluate(X_test.as_matrix(), y_test, batch_size=16)\n",
    "score = model.evaluate(xval, yval, batch_size=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,TimeDistributedDense\n",
    "from keras.layers import LSTM, Dropout\n",
    "\n",
    "from pandas.tseries.offsets import *\n",
    "from keras import callbacks\n",
    "\n",
    "remote = callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "\n",
    "length_of_sequences = 61\n",
    "in_out_neurons = 1\n",
    "hidden_neurons = 61\n",
    "bs = 61\n",
    "\n",
    "model = Sequential()  \n",
    "model.add(LSTM(hidden_neurons, batch_input_shape=(None, length_of_sequences, in_out_neurons), return_sequences=False))\n",
    "#model.add(LSTM(hidden_neurons, input_dim=length_of_sequences, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(TimeDistributedDense(length_of_sequences))\n",
    "model.add(Dense(in_out_neurons))\n",
    "model.add(Activation(\"linear\"))  \n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "model.fit(xtrain, ytrain, batch_size=bs, nb_epoch=15, validation_split=0.2, callbacks=[remote])  \n",
    "     \n",
    "#model.fit(X_train, y_train, batch_size=bs, nb_epoch=15, validation_data=(X_test, y_test), callbacks=[remote])     \n",
    "     \n",
    "predicted = model.predict(xval) \n",
    "dataf =  pd.DataFrame(predicted[:1200])\n",
    "dataf.columns = [\"predict\"]\n",
    "dataf[\"input\"] = yval[:1200]\n",
    "dataf.plot(figsize=(15, 5))\n",
    "\n",
    "#score = model.evaluate(X_test.as_matrix(), y_test, batch_size=16)\n",
    "score = model.evaluate(xval, yval, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "means = {}\n",
    "\n",
    "for x in ids:\n",
    "    ys = df[df[\"id\"] == x].y\n",
    "    ma = pd.ewma(ys,span=5)\n",
    "    #means[i] = ys.mean()\n",
    "    means[i] = ma[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import johnsonsu\n",
    "\n",
    "a, b = 2.55439557416, 2.24822816797\n",
    "mean, var, skew, kurt = johnsonsu.stats(a, b, moments='mvsk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[means[d] for d in list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.sample(means.values(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randy = random.sample(means.values(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rs(mu, sig, symlist):\n",
    "    \n",
    "    samp=[]\n",
    "    \n",
    "    for i in symlist:\n",
    "        print i, mu[i], sig[i]\n",
    "        s = np.random.normal(mu[i],sig[i])\n",
    "        samp.append(s)\n",
    "    return samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means = {}\n",
    "std = {}\n",
    "for i in ids:\n",
    "    ys = df[df[\"id\"] == i].y\n",
    "    #ma = pd.ewma(ys,span=5)\n",
    "    means[i] = ys.mean()\n",
    "    std[i] = ys.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = rs(means,std,ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = np.random.normal(means[1],std[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samp.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "regression = linear_model.ElasticNetCV()\n",
    "pca = decomposition.PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('regression', regression)])\n",
    "\n",
    "cols = [x for x in df.columns.values if x not in [\"id\", \"timestamp\",\"y\",\"cumprod\"]]\n",
    "l = len(cols)\n",
    "dfj = dfi.fillna(0)\n",
    "target = dfj.pop('y')\n",
    "ts = dfj.pop('timestamp')\n",
    "dfj = dfi.drop([\"id\",\"y\",\"cumprod\"],axis=1)\n",
    "dfj=dfj.fillna(0)\n",
    "features = dfj.values\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
