{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import kagglegym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start environment\n",
    "env = kagglegym.make()\n",
    "observation = env.reset()\n",
    "train = observation.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "# https://www.kaggle.com/bguberfain/two-sigma-financial-modeling/univariate-model-with-clip/run/482189/code\n",
    "# Clipped target value range to use\n",
    "low_y_cut = -0.086093\n",
    "high_y_cut = 0.093497\n",
    "\n",
    "y_is_above_cut = (train.y > high_y_cut)\n",
    "y_is_below_cut = (train.y < low_y_cut)\n",
    "y_is_within_cut = (~y_is_above_cut & ~y_is_below_cut)\n",
    "\n",
    "# Select the features to use\n",
    "excl = ['id', 'sample', 'y', 'timestamp']\n",
    "#feature_vars = [c for c in train.columns if c not in excl]\n",
    "features_to_use = ['technical_30', 'technical_20', 'technical_19', 'fundamental_11']\n",
    "target_var = ['y']\n",
    "\n",
    "features = train.loc[y_is_within_cut, features_to_use]\n",
    "X_train = features.values\n",
    "\n",
    "targets = train.loc[y_is_within_cut, target_var]\n",
    "y_train = targets.values\n",
    "\n",
    "im = pp.Imputer(strategy='median')\n",
    "X_train = im.fit_transform(X_train)\n",
    "X_scaler = pp.RobustScaler()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "y_scaler = pp.RobustScaler()\n",
    "y_train = y_scaler.fit_transform(y_train.reshape([-1,1]))\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=features_to_use)\n",
    "y_train = pd.DataFrame(y_train, columns=target_var)\n",
    "preprocess_dict = {'fillna': im, 'X_scaler': X_scaler, 'y_scaler': y_scaler}\n",
    "\n",
    "del y_is_above_cut, y_is_below_cut, excl, targets, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l2_coef=0.0001\n",
    "drop_coef=0.7\n",
    "shape=[len(features_to_use),256,64,32,1]\n",
    "model = Sequential()\n",
    "model.add(LSTM(shape[1], input_shape=(timesteps, shape[0])))\n",
    "#model.add(Dense(shape[2], input_dim=shape[0], init='he_uniform', W_regularizer=l2(l2_coef)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(drop_coef))\n",
    "#model.add(Dense(shape[3], init='he_uniform', W_regularizer=l2(l2_coef)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(drop_coef))\n",
    "model.add(Dense(shape[4], init=\"he_uniform\", W_regularizer=l2(l2_coef)))\n",
    "model.add(Activation(\"linear\"))\n",
    "model.compile(loss=\"mse\",optimizer=\"adam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "(796880L, 1L, 11L)\n",
      "Epoch 1/1\n",
      "796880/796880 [==============================] - 132s - loss: 1.1281   \n",
      "('Done! Training time:', 147.58500003814697)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model\")\n",
    "t0 = time()\n",
    "timesteps = 1\n",
    "X_train_ts = pad_sequences(np.reshape(X_train.values, (X_train.values.shape[0], timesteps, X_train.values.shape[1])))\n",
    "print(X_train_ts.shape)\n",
    "model.fit(X_train_ts, y_train.values, nb_epoch=1,batch_size=64);\n",
    "print(\"Done! Training time:\", time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on training set\n",
      "('Done! Eval time:', 18.348999977111816)\n",
      "('Mean squared error for train dataset:', 1.1251106349379048)\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model on training set\")\n",
    "t0 = time()\n",
    "m1_loss = model.evaluate(X_train_ts, y_train.values, batch_size=64, verbose=0)\n",
    "print(\"Done! Eval time:\",time() - t0)\n",
    "print(\"Mean squared error for train dataset:\",m1_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting target on training dataset\n",
      "('Done! Prediction time:', 16.23300004005432)\n",
      "('R2 score for train dataset', 0.0009135742732649943)\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting target on training dataset\")\n",
    "t0 = time()\n",
    "m1_preds = model.predict(X_train_ts, batch_size=64, verbose=0)\n",
    "score = r2_score(y_train, m1_preds)\n",
    "print(\"Done! Prediction time:\",time() - t0)\n",
    "print(\"R2 score for train dataset\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict-step-predict routine ################################################################################\n",
    "def gen_preds(model, preprocess_dict, features_to_use, print_info=True):\n",
    "    env = kagglegym.make()\n",
    "    # We get our initial observation by calling \"reset\"\n",
    "    observation = env.reset()\n",
    "\n",
    "    im = preprocess_dict['fillna']\n",
    "    X_scaler = preprocess_dict['X_scaler']\n",
    "    y_scaler = preprocess_dict['y_scaler']\n",
    "    \n",
    "    reward = 0.0\n",
    "    reward_log = []\n",
    "    timestamps_log = []\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "\n",
    "    total_pos = []\n",
    "    total_neg = []\n",
    "\n",
    "    print(\"Predicting\")\n",
    "    t0= time()\n",
    "    while True:\n",
    "    #    observation.features.fillna(mean_values, inplace=True)\n",
    "\n",
    "        # Predict with model\n",
    "        features_dnn = im.transform(observation.features.loc[:,features_to_use].values)\n",
    "        features_dnn = X_scaler.transform(features_dnn)\n",
    "        \n",
    "        features_dnn_ts = pad_sequences(np.reshape(features_dnn,\n",
    "                                                   (features_dnn.shape[0], timesteps, features_dnn.shape[1])))\n",
    "\n",
    "        y_dnn = model.predict(features_dnn_ts,batch_size=32,verbose=0).clip(low_y_cut, high_y_cut)\n",
    "\n",
    "        # Fill target df with predictions \n",
    "        observation.target.y = y_scaler.inverse_transform(y_dnn)\n",
    "\n",
    "        observation.target.fillna(0, inplace=True)\n",
    "        target = observation.target\n",
    "        timestamp = observation.features[\"timestamp\"][0]\n",
    "        \n",
    "        observation, reward, done, info = env.step(target)\n",
    "\n",
    "        timestamps_log.append(timestamp)\n",
    "        reward_log.append(reward)\n",
    "\n",
    "        if (reward < 0):\n",
    "            neg_count += 1\n",
    "        else:\n",
    "            pos_count += 1\n",
    "\n",
    "        total_pos.append(pos_count)\n",
    "        total_neg.append(neg_count)\n",
    "        \n",
    "        if timestamp % 100 == 0:\n",
    "            if print_info:\n",
    "                print(\"Timestamp #{}\".format(timestamp))\n",
    "                print(\"Step reward:\", reward)\n",
    "                print(\"Mean reward:\", np.mean(reward_log[-timestamp:]))\n",
    "                print(\"Positive rewards count: {0}, Negative rewards count: {1}\".format(pos_count, neg_count))\n",
    "                print(\"Positive reward %:\", pos_count / (pos_count + neg_count) * 100)\n",
    "\n",
    "            pos_count = 0\n",
    "            neg_count = 0\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    print(\"Done: %.1fs\" % (time() - t0))\n",
    "    print(\"Total reward sum:\", np.sum(reward_log))\n",
    "    print(\"Final reward mean:\", np.mean(reward_log))\n",
    "    print(\"Total positive rewards count: {0}, Total negative rewards count: {1}\".format(np.sum(total_pos),\n",
    "                                                                                        np.sum(total_neg)))\n",
    "    print(\"Final positive reward %:\", np.sum(total_pos) / (np.sum(total_pos) + np.sum(total_neg)) * 100)\n",
    "    print(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n",
      "Timestamp #1000\n",
      "('Step reward:', -0.047944348833231405)\n",
      "('Mean reward:', -0.13574372345434818)\n",
      "Positive rewards count: 5, Negative rewards count: 90\n",
      "('Positive reward %:', 0)\n",
      "Timestamp #1100\n",
      "('Step reward:', -0.010028695105360324)\n",
      "('Mean reward:', -0.1286508996829453)\n",
      "Positive rewards count: 10, Negative rewards count: 90\n",
      "('Positive reward %:', 0)\n",
      "Timestamp #1200\n",
      "('Step reward:', -0.099286317618938399)\n",
      "('Mean reward:', -0.1275602984619976)\n",
      "Positive rewards count: 13, Negative rewards count: 87\n",
      "('Positive reward %:', 0)\n",
      "Timestamp #1300\n",
      "('Step reward:', -0.083820951367486782)\n",
      "('Mean reward:', -0.127840929347489)\n",
      "Positive rewards count: 9, Negative rewards count: 91\n",
      "('Positive reward %:', 0)\n",
      "Timestamp #1400\n",
      "('Step reward:', -0.15737361172250902)\n",
      "('Mean reward:', -0.12777189829165031)\n",
      "Positive rewards count: 9, Negative rewards count: 91\n",
      "('Positive reward %:', 0)\n",
      "Timestamp #1500\n",
      "('Step reward:', -0.17468773830697087)\n",
      "('Mean reward:', -0.12639306373567208)\n",
      "Positive rewards count: 13, Negative rewards count: 87\n",
      "('Positive reward %:', 0)\n",
      "Timestamp #1600\n",
      "('Step reward:', -0.17203299682806061)\n",
      "('Mean reward:', -0.13104932430716584)\n",
      "Positive rewards count: 16, Negative rewards count: 84\n",
      "('Positive reward %:', 0)\n",
      "Timestamp #1700\n",
      "('Step reward:', 0.049091842145116631)\n",
      "('Mean reward:', -0.13339052305468468)\n",
      "Positive rewards count: 12, Negative rewards count: 88\n",
      "('Positive reward %:', 0)\n",
      "Timestamp #1800\n",
      "('Step reward:', -0.084478333803161637)\n",
      "('Mean reward:', -0.13351366075275783)\n",
      "Positive rewards count: 9, Negative rewards count: 91\n",
      "('Positive reward %:', 0)\n",
      "Done: 61.8s\n",
      "('Total reward sum:', -120.91445750303529)\n",
      "('Final reward mean:', -0.13331252205406316)\n",
      "Total positive rewards count: 5226, Total negative rewards count: 39812\n",
      "('Final positive reward %:', 0)\n",
      "{'public_score': -0.012539032584455722}\n"
     ]
    }
   ],
   "source": [
    "gen_preds(model, preprocess_dict, features_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
