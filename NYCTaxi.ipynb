{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from datetime import timedelta\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [16, 10]\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1987)\n",
    "N = 100000 # number of sample rows in plots\n",
    "t0 = dt.datetime.now()\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "#weather = pd.read_csv('weather_data_nyc_centralpark_2016.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip_duration and datetimes are ok.\n"
     ]
    }
   ],
   "source": [
    "train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\n",
    "test['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\n",
    "train.loc[:, 'pickup_date'] = train['pickup_datetime'].dt.date\n",
    "test.loc[:, 'pickup_date'] = test['pickup_datetime'].dt.date\n",
    "train['dropoff_datetime'] = pd.to_datetime(train.dropoff_datetime)\n",
    "train['store_and_fwd_flag'] = 1 * (train.store_and_fwd_flag.values == 'Y')\n",
    "test['store_and_fwd_flag'] = 1 * (test.store_and_fwd_flag.values == 'Y')\n",
    "train['check_trip_duration'] = (train['dropoff_datetime'] - train['pickup_datetime']).map(lambda x: x.total_seconds())\n",
    "duration_difference = train[np.abs(train['check_trip_duration'].values  - train['trip_duration'].values) > 1]\n",
    "train['log_trip_duration'] = np.log(train['trip_duration'].values + 1)\n",
    "print('Trip_duration and datetimes are ok.') if len(duration_difference[['pickup_datetime', 'dropoff_datetime', 'trip_duration', 'check_trip_duration']]) == 0 else print('Ooops.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords = np.vstack((train[['pickup_latitude', 'pickup_longitude']].values,\n",
    "                    train[['dropoff_latitude', 'dropoff_longitude']].values,\n",
    "                    test[['pickup_latitude', 'pickup_longitude']].values,\n",
    "                    test[['dropoff_latitude', 'dropoff_longitude']].values))\n",
    "\n",
    "pca = PCA().fit(coords)\n",
    "train['pickup_pca0'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 0]\n",
    "train['pickup_pca1'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 1]\n",
    "train['dropoff_pca0'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n",
    "train['dropoff_pca1'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n",
    "test['pickup_pca0'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 0]\n",
    "test['pickup_pca1'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 1]\n",
    "test['dropoff_pca0'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n",
    "test['dropoff_pca1'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def haversine_array(lat1, lng1, lat2, lng2):\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h\n",
    "\n",
    "def dummy_manhattan_distance(lat1, lng1, lat2, lng2):\n",
    "    a = haversine_array(lat1, lng1, lat1, lng2)\n",
    "    b = haversine_array(lat1, lng1, lat2, lng1)\n",
    "    return a + b\n",
    "\n",
    "def bearing_array(lat1, lng1, lat2, lng2):\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lng_delta_rad = np.radians(lng2 - lng1)\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    y = np.sin(lng_delta_rad) * np.cos(lat2)\n",
    "    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n",
    "    return np.degrees(np.arctan2(y, x))\n",
    "\n",
    "train.loc[:, 'distance_haversine'] = haversine_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train.loc[:, 'direction'] = bearing_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train.loc[:, 'pca_manhattan'] = np.abs(train['dropoff_pca1'] - train['pickup_pca1']) + np.abs(train['dropoff_pca0'] - train['pickup_pca0'])\n",
    "\n",
    "test.loc[:, 'distance_haversine'] = haversine_array(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n",
    "test.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n",
    "test.loc[:, 'direction'] = bearing_array(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n",
    "test.loc[:, 'pca_manhattan'] = np.abs(test['dropoff_pca1'] - test['pickup_pca1']) + np.abs(test['dropoff_pca0'] - test['pickup_pca0'])\n",
    "\n",
    "train.loc[:, 'center_latitude'] = (train['pickup_latitude'].values + train['dropoff_latitude'].values) / 2\n",
    "train.loc[:, 'center_longitude'] = (train['pickup_longitude'].values + train['dropoff_longitude'].values) / 2\n",
    "test.loc[:, 'center_latitude'] = (test['pickup_latitude'].values + test['dropoff_latitude'].values) / 2\n",
    "test.loc[:, 'center_longitude'] = (test['pickup_longitude'].values + test['dropoff_longitude'].values) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.loc[:, 'pickup_weekday'] = train['pickup_datetime'].dt.weekday\n",
    "train.loc[:, 'pickup_hour_weekofyear'] = train['pickup_datetime'].dt.weekofyear\n",
    "train.loc[:, 'pickup_hour'] = train['pickup_datetime'].dt.hour\n",
    "train.loc[:, 'pickup_minute'] = train['pickup_datetime'].dt.minute\n",
    "train.loc[:, 'pickup_dt'] = (train['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\n",
    "train.loc[:, 'pickup_week_hour'] = train['pickup_weekday'] * 24 + train['pickup_hour']\n",
    "\n",
    "test.loc[:, 'pickup_weekday'] = test['pickup_datetime'].dt.weekday\n",
    "test.loc[:, 'pickup_hour_weekofyear'] = test['pickup_datetime'].dt.weekofyear\n",
    "test.loc[:, 'pickup_hour'] = test['pickup_datetime'].dt.hour\n",
    "test.loc[:, 'pickup_minute'] = test['pickup_datetime'].dt.minute\n",
    "test.loc[:, 'pickup_dt'] = (test['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\n",
    "test.loc[:, 'pickup_week_hour'] = test['pickup_weekday'] * 24 + test['pickup_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.loc[:, 'avg_speed_h'] = 1000 * train['distance_haversine'] / train['trip_duration']\n",
    "train.loc[:, 'avg_speed_m'] = 1000 * train['distance_dummy_manhattan'] / train['trip_duration']\n",
    "train.loc[:, 'pickup_lat_bin'] = np.round(train['pickup_latitude'], 3)\n",
    "train.loc[:, 'pickup_long_bin'] = np.round(train['pickup_longitude'], 3)\n",
    "# Average speed for regions\n",
    "gby_cols = ['pickup_lat_bin', 'pickup_long_bin']\n",
    "coord_speed = train.groupby(gby_cols).mean()[['avg_speed_h']].reset_index()\n",
    "coord_count = train.groupby(gby_cols).count()[['id']].reset_index()\n",
    "coord_stats = pd.merge(coord_speed, coord_count, on=gby_cols)\n",
    "coord_stats = coord_stats[coord_stats['id'] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.loc[:, 'pickup_lat_bin'] = np.round(train['pickup_latitude'], 3)\n",
    "train.loc[:, 'pickup_long_bin'] = np.round(train['pickup_longitude'], 3)\n",
    "train.loc[:, 'pickup_lat_bin'] = np.round(train['pickup_latitude'], 2)\n",
    "train.loc[:, 'pickup_long_bin'] = np.round(train['pickup_longitude'], 2)\n",
    "train.loc[:, 'center_lat_bin'] = np.round(train['center_latitude'], 2)\n",
    "train.loc[:, 'center_long_bin'] = np.round(train['center_longitude'], 2)\n",
    "train.loc[:, 'pickup_dt_bin'] = (train['pickup_dt'] // (3 * 3600))\n",
    "test.loc[:, 'pickup_lat_bin'] = np.round(test['pickup_latitude'], 2)\n",
    "test.loc[:, 'pickup_long_bin'] = np.round(test['pickup_longitude'], 2)\n",
    "test.loc[:, 'center_lat_bin'] = np.round(test['center_latitude'], 2)\n",
    "test.loc[:, 'center_long_bin'] = np.round(test['center_longitude'], 2)\n",
    "test.loc[:, 'pickup_dt_bin'] = (test['pickup_dt'] // (3 * 3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time till clustering: 60 seconds\n"
     ]
    }
   ],
   "source": [
    "sample_ind = np.random.permutation(len(coords))[:500000]\n",
    "kmeans = MiniBatchKMeans(n_clusters=100, batch_size=10000).fit(coords[sample_ind])\n",
    "\n",
    "train.loc[:, 'pickup_cluster'] = kmeans.predict(train[['pickup_latitude', 'pickup_longitude']])\n",
    "train.loc[:, 'dropoff_cluster'] = kmeans.predict(train[['dropoff_latitude', 'dropoff_longitude']])\n",
    "test.loc[:, 'pickup_cluster'] = kmeans.predict(test[['pickup_latitude', 'pickup_longitude']])\n",
    "test.loc[:, 'dropoff_cluster'] = kmeans.predict(test[['dropoff_latitude', 'dropoff_longitude']])\n",
    "t1 = dt.datetime.now()\n",
    "print('Time till clustering: %i seconds' % (t1 - t0).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for gby_col in ['pickup_hour', 'pickup_date', 'pickup_dt_bin',\n",
    "               'pickup_week_hour', 'pickup_cluster', 'dropoff_cluster']:\n",
    "    gby = train.groupby(gby_col).mean()[['avg_speed_h', 'avg_speed_m', 'log_trip_duration']]\n",
    "    gby.columns = ['%s_gby_%s' % (col, gby_col) for col in gby.columns]\n",
    "    train = pd.merge(train, gby, how='left', left_on=gby_col, right_index=True)\n",
    "    test = pd.merge(test, gby, how='left', left_on=gby_col, right_index=True)\n",
    "\n",
    "for gby_cols in [['center_lat_bin', 'center_long_bin'],\n",
    "                 ['pickup_hour', 'center_lat_bin', 'center_long_bin'],\n",
    "                 ['pickup_hour', 'pickup_cluster'],  ['pickup_hour', 'dropoff_cluster'],\n",
    "                 ['pickup_cluster', 'dropoff_cluster']]:\n",
    "    coord_speed = train.groupby(gby_cols).mean()[['avg_speed_h']].reset_index()\n",
    "    coord_count = train.groupby(gby_cols).count()[['id']].reset_index()\n",
    "    coord_stats = pd.merge(coord_speed, coord_count, on=gby_cols)\n",
    "    coord_stats = coord_stats[coord_stats['id'] > 100]\n",
    "    coord_stats.columns = gby_cols + ['avg_speed_h_%s' % '_'.join(gby_cols), 'cnt_%s' %  '_'.join(gby_cols)]\n",
    "    train = pd.merge(train, coord_stats, how='left', on=gby_cols)\n",
    "    test = pd.merge(test, coord_stats, how='left', on=gby_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_freq = '60min'\n",
    "df_all = pd.concat((train, test))[['id', 'pickup_datetime', 'pickup_cluster', 'dropoff_cluster']]\n",
    "train.loc[:, 'pickup_datetime_group'] = train['pickup_datetime'].dt.round(group_freq)\n",
    "test.loc[:, 'pickup_datetime_group'] = test['pickup_datetime'].dt.round(group_freq)\n",
    "\n",
    "# Count trips over 60min\n",
    "df_counts = df_all.set_index('pickup_datetime')[['id']].sort_index()\n",
    "df_counts['count_60min'] = df_counts.isnull().rolling(group_freq).count()['id']\n",
    "train = train.merge(df_counts, on='id', how='left')\n",
    "test = test.merge(df_counts, on='id', how='left')\n",
    "\n",
    "# Count how many trips are going to each cluster over time\n",
    "dropoff_counts = df_all \\\n",
    "    .set_index('pickup_datetime') \\\n",
    "    .groupby([pd.TimeGrouper(group_freq), 'dropoff_cluster']) \\\n",
    "    .agg({'id': 'count'}) \\\n",
    "    .reset_index().set_index('pickup_datetime') \\\n",
    "    .groupby('dropoff_cluster').rolling('240min').mean() \\\n",
    "    .drop('dropoff_cluster', axis=1) \\\n",
    "    .reset_index().set_index('pickup_datetime').shift(freq='-120min').reset_index() \\\n",
    "    .rename(columns={'pickup_datetime': 'pickup_datetime_group', 'id': 'dropoff_cluster_count'})\n",
    "\n",
    "train['dropoff_cluster_count'] = train[['pickup_datetime_group', 'dropoff_cluster']].merge(dropoff_counts, on=['pickup_datetime_group', 'dropoff_cluster'], how='left')['dropoff_cluster_count'].fillna(0)\n",
    "test['dropoff_cluster_count'] = test[['pickup_datetime_group', 'dropoff_cluster']].merge(dropoff_counts, on=['pickup_datetime_group', 'dropoff_cluster'], how='left')['dropoff_cluster_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count how many trips are going from each cluster over time\n",
    "df_all = pd.concat((train, test))[['id', 'pickup_datetime', 'pickup_cluster', 'dropoff_cluster']]\n",
    "pickup_counts = df_all \\\n",
    "    .set_index('pickup_datetime') \\\n",
    "    .groupby([pd.TimeGrouper(group_freq), 'pickup_cluster']) \\\n",
    "    .agg({'id': 'count'}) \\\n",
    "    .reset_index().set_index('pickup_datetime') \\\n",
    "    .groupby('pickup_cluster').rolling('240min').mean() \\\n",
    "    .drop('pickup_cluster', axis=1) \\\n",
    "    .reset_index().set_index('pickup_datetime').shift(freq='-120min').reset_index() \\\n",
    "    .rename(columns={'pickup_datetime': 'pickup_datetime_group', 'id': 'pickup_cluster_count'})\n",
    "\n",
    "train['pickup_cluster_count'] = train[['pickup_datetime_group', 'pickup_cluster']].merge(pickup_counts, on=['pickup_datetime_group', 'pickup_cluster'], how='left')['pickup_cluster_count'].fillna(0)\n",
    "test['pickup_cluster_count'] = test[['pickup_datetime_group', 'pickup_cluster']].merge(pickup_counts, on=['pickup_datetime_group', 'pickup_cluster'], how='left')['pickup_cluster_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(train.median())\n",
    "test = test.fillna(test.median())\n",
    "fr1 = pd.read_csv('fastest_routes_train_part_1.csv')\n",
    "fr2 = pd.read_csv('fastest_routes_train_part_2.csv')\n",
    "test_street_info = pd.read_csv('fastest_routes_test.csv')\n",
    "train_street_info = pd.concat((fr1, fr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dicc(z):\n",
    "    return dict(zip(z[0],z[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=train_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()\n",
    "b=train_street_info['distance_per_step'].apply(lambda x: x.split(\"|\")).values.tolist()\n",
    "c=train_street_info['travel_time_per_step'].apply(lambda x: x.split(\"|\")).values.tolist()\n",
    "u = list(zip(a,b))\n",
    "v = list(zip(a,c))\n",
    "train_dist_dict = np.apply_along_axis(dicc,1,u)\n",
    "train_time_dict = np.apply_along_axis(dicc,1,v)\n",
    "del a\n",
    "del b\n",
    "del c\n",
    "del u \n",
    "del v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=test_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()\n",
    "b=test_street_info['distance_per_step'].apply(lambda x: x.split(\"|\")).values.tolist()\n",
    "c=test_street_info['travel_time_per_step'].apply(lambda x: x.split(\"|\")).values.tolist()\n",
    "u = list(zip(a,b))\n",
    "v = list(zip(a,c))\n",
    "test_dist_dict = np.apply_along_axis(dicc,1,u)\n",
    "test_time_dict = np.apply_along_axis(dicc,1,v)\n",
    "del a\n",
    "del b\n",
    "del c\n",
    "del u\n",
    "del v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>starting_street</th>\n",
       "      <th>end_street</th>\n",
       "      <th>total_distance</th>\n",
       "      <th>total_travel_time</th>\n",
       "      <th>number_of_steps</th>\n",
       "      <th>street_for_each_step</th>\n",
       "      <th>distance_per_step</th>\n",
       "      <th>travel_time_per_step</th>\n",
       "      <th>step_maneuvers</th>\n",
       "      <th>...</th>\n",
       "      <th>rotary_ds</th>\n",
       "      <th>merge_ds</th>\n",
       "      <th>continue_ds</th>\n",
       "      <th>onramp_ds</th>\n",
       "      <th>offramp_ds</th>\n",
       "      <th>fork_ds</th>\n",
       "      <th>turn_ds</th>\n",
       "      <th>roundabout_ds</th>\n",
       "      <th>roundabout_turn_ds</th>\n",
       "      <th>street_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>Columbus Circle</td>\n",
       "      <td>East 65th Street</td>\n",
       "      <td>2009.1</td>\n",
       "      <td>164.9</td>\n",
       "      <td>5</td>\n",
       "      <td>Columbus Circle|Central Park West|65th Street ...</td>\n",
       "      <td>0|576.4|885.6|547.1|0</td>\n",
       "      <td>0|61.1|60.1|43.7|0</td>\n",
       "      <td>depart|rotary|turn|new name|arrive</td>\n",
       "      <td>...</td>\n",
       "      <td>576.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>885.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2377394</td>\n",
       "      <td>2nd Avenue</td>\n",
       "      <td>Washington Square West</td>\n",
       "      <td>2513.2</td>\n",
       "      <td>332.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2nd Avenue|East 13th Street|5th Avenue|Washing...</td>\n",
       "      <td>877.3|836.5|496.1|164.2|139.1|0</td>\n",
       "      <td>111.7|109|69.9|25.8|15.6|0</td>\n",
       "      <td>depart|turn|turn|end of road|continue|arrive</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>496.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3504673</td>\n",
       "      <td>Greenwich Street</td>\n",
       "      <td>Broadway</td>\n",
       "      <td>1779.4</td>\n",
       "      <td>235.8</td>\n",
       "      <td>4</td>\n",
       "      <td>Greenwich Street|Park Place|Broadway|Broadway</td>\n",
       "      <td>644.2|379.9|755.3|0</td>\n",
       "      <td>80.5|50.8|104.5|0</td>\n",
       "      <td>depart|turn|end of road|arrive</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>379.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id2181028</td>\n",
       "      <td>Broadway</td>\n",
       "      <td>West 81st Street</td>\n",
       "      <td>1614.9</td>\n",
       "      <td>140.1</td>\n",
       "      <td>5</td>\n",
       "      <td>Broadway|West 86th Street|Columbus Avenue|West...</td>\n",
       "      <td>617|427.4|412.2|158.3|0</td>\n",
       "      <td>56|36|37.8|10.3|0</td>\n",
       "      <td>depart|turn|turn|turn|arrive</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id0801584</td>\n",
       "      <td>Lexington Avenue</td>\n",
       "      <td>West 31st Street</td>\n",
       "      <td>1393.5</td>\n",
       "      <td>189.4</td>\n",
       "      <td>5</td>\n",
       "      <td>Lexington Avenue|East 27th Street|Madison Aven...</td>\n",
       "      <td>18.9|311.9|313.3|749.4|0</td>\n",
       "      <td>6.3|42.9|48.4|91.8|0</td>\n",
       "      <td>depart|turn|turn|turn|arrive</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>749.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   starting_street              end_street  total_distance  \\\n",
       "0  id2875421   Columbus Circle        East 65th Street          2009.1   \n",
       "1  id2377394        2nd Avenue  Washington Square West          2513.2   \n",
       "2  id3504673  Greenwich Street                Broadway          1779.4   \n",
       "3  id2181028          Broadway        West 81st Street          1614.9   \n",
       "4  id0801584  Lexington Avenue        West 31st Street          1393.5   \n",
       "\n",
       "   total_travel_time  number_of_steps  \\\n",
       "0              164.9                5   \n",
       "1              332.0                6   \n",
       "2              235.8                4   \n",
       "3              140.1                5   \n",
       "4              189.4                5   \n",
       "\n",
       "                                street_for_each_step  \\\n",
       "0  Columbus Circle|Central Park West|65th Street ...   \n",
       "1  2nd Avenue|East 13th Street|5th Avenue|Washing...   \n",
       "2      Greenwich Street|Park Place|Broadway|Broadway   \n",
       "3  Broadway|West 86th Street|Columbus Avenue|West...   \n",
       "4  Lexington Avenue|East 27th Street|Madison Aven...   \n",
       "\n",
       "                 distance_per_step        travel_time_per_step  \\\n",
       "0            0|576.4|885.6|547.1|0          0|61.1|60.1|43.7|0   \n",
       "1  877.3|836.5|496.1|164.2|139.1|0  111.7|109|69.9|25.8|15.6|0   \n",
       "2              644.2|379.9|755.3|0           80.5|50.8|104.5|0   \n",
       "3          617|427.4|412.2|158.3|0           56|36|37.8|10.3|0   \n",
       "4         18.9|311.9|313.3|749.4|0        6.3|42.9|48.4|91.8|0   \n",
       "\n",
       "                                 step_maneuvers      ...      rotary_ds  \\\n",
       "0            depart|rotary|turn|new name|arrive      ...          576.4   \n",
       "1  depart|turn|turn|end of road|continue|arrive      ...              0   \n",
       "2                depart|turn|end of road|arrive      ...              0   \n",
       "3                  depart|turn|turn|turn|arrive      ...              0   \n",
       "4                  depart|turn|turn|turn|arrive      ...              0   \n",
       "\n",
       "  merge_ds  continue_ds  onramp_ds  offramp_ds  fork_ds  turn_ds  \\\n",
       "0        0            0          0           0        0    885.6   \n",
       "1        0        139.1          0           0        0    496.1   \n",
       "2        0            0          0           0        0    379.9   \n",
       "3        0            0          0           0        0    158.3   \n",
       "4        0            0          0           0        0    749.4   \n",
       "\n",
       "   roundabout_ds  roundabout_turn_ds  street_count  \n",
       "0              0                   0             5  \n",
       "1              0                   0             6  \n",
       "2              0                   0             4  \n",
       "3              0                   0             5  \n",
       "4              0                   0             5  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_street_info['num_left_turns'] = [x.count('left') for x in train_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['num_left_turns'] = [x.count('left') for x in test_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['num_slightleft_turns'] = [x.count('slight left') for x in train_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['num_slightleft_turns'] = [x.count('slight left') for x in test_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['num_sharpleft_turns'] = [x.count('sharp left') for x in train_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['num_sharpleft_turns'] = [x.count('sharp left') for x in test_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "\n",
    "train_street_info['num_uturns'] = [x.count('uturn') for x in train_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['num_uturns'] = [x.count('uturn') for x in test_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['num_none'] = [x.count('none') for x in train_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['num_none'] = [x.count('none') for x in test_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['num_straight'] = [x.count('straight') for x in train_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['num_straight'] = [x.count('straight') for x in test_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "\n",
    "train_street_info['num_right_turns'] = [x.count('right') for x in train_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['num_right_turns'] = [x.count('right') for x in test_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['num_slightright_turns'] = [x.count('slight right') for x in train_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['num_slightright_turns'] = [x.count('slight right') for x in test_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['num_sharpright_turns'] = [x.count('sharp right') for x in train_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['num_sharpright_turns'] = [x.count('sharp right') for x in test_street_info['step_direction'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "\n",
    "train_street_info['end_of_road_count'] = [x.count('end of road') for x in train_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['end_of_road_count'] = [x.count('end of road') for x in test_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['new_name_count'] = [x.count('new name') for x in train_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['new_name_count'] = [x.count('new name') for x in test_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['rotary_count'] = [x.count('rotary') for x in train_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['rotary_count'] = [x.count('rotary') for x in test_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['merge_count'] = [x.count('merge') for x in train_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['merge_count'] = [x.count('merge') for x in test_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['continue_count'] = [x.count('continue') for x in train_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['continue_count'] = [x.count('continue') for x in test_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['onramp_count'] = [x.count('on ramp') for x in train_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['onramp_count'] = [x.count('on ramp') for x in test_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['offramp_count'] = [x.count('off ramp') for x in train_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['offramp_count'] = [x.count('off ramp') for x in test_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['fork_count'] = [x.count('fork') for x in train_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['fork_count'] = [x.count('fork') for x in test_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['turn_count'] = [x.count('turn') for x in train_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['turn_count'] = [x.count('turn') for x in test_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['roundabout_count'] = [x.count('roundabout') for x in train_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['roundabout_count'] = [x.count('roudabout') for x in test_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "train_street_info['roundabout_turn_count'] = [x.count('roundabout turn') for x in train_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['roundabout_turn_count'] = [x.count('roundabout turn') for x in test_street_info['step_maneuvers'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "\n",
    "train_street_info['arrive_tm'] = [d['arrive'] if 'arrive' in d else 0 for d in train_time_dict]\n",
    "test_street_info['arrive_tm'] = [d['arrive'] if 'arrive' in d else 0 for d in test_time_dict]\n",
    "train_street_info['depart_tm'] = [d['depart'] if 'depart' in d else 0 for d in train_time_dict]\n",
    "test_street_info['depart_tm'] = [d['depart'] if 'depart' in d else 0 for d in test_time_dict]\n",
    "train_street_info['end_of_road_tm'] = [d['end of road'] if 'end of road' in d else 0 for d in train_time_dict]\n",
    "test_street_info['end_of_road_tm'] = [d['end of road'] if 'end of road' in d else 0 for d in test_time_dict]\n",
    "train_street_info['new_name_tm'] = [d['new name'] if 'new name' in d else 0 for d in train_time_dict]\n",
    "test_street_info['new_name_tm'] = [d['new name'] if 'new name' in d else 0 for d in test_time_dict]\n",
    "train_street_info['rotary_tm'] = [d['rotary'] if 'rotary' in d else 0 for d in train_time_dict ]\n",
    "test_street_info['rotary_tm'] = [d['rotary'] if 'rotary' in d else 0 for d in test_time_dict]\n",
    "train_street_info['merge_tm'] = [d['merge'] if 'merge' in d else 0 for d in train_time_dict]\n",
    "test_street_info['merge_tm'] = [d['merge'] if 'merge' in d else 0 for d in test_time_dict]\n",
    "train_street_info['continue_tm'] = [d['continue'] if 'continue' in d else 0 for d in train_time_dict]\n",
    "test_street_info['continue_tm'] = [d['continue'] if 'continue' in d else 0 for d in test_time_dict]\n",
    "train_street_info['onramp_tm'] = [d['on ramp'] if 'on ramp' in d else 0 for d in train_time_dict]\n",
    "test_street_info['onramp_tm'] = [d['on ramp'] if 'on ramp' in d else 0 for d in test_time_dict]\n",
    "train_street_info['offramp_tm'] = [d['off ramp'] if 'off ramp' in d else 0 for d in train_time_dict]\n",
    "test_street_info['offramp_tm'] = [d['off ramp'] if 'off ramp' in d else 0 for d in test_time_dict]\n",
    "train_street_info['fork_tm'] = [d['fork'] if 'fork' in d else 0 for d in train_time_dict]\n",
    "test_street_info['fork_tm'] = [d['fork'] if 'fork' in d else 0 for d in test_time_dict]\n",
    "train_street_info['turn_tm'] = [d['turn'] if 'turn' in d else 0 for d in train_time_dict]\n",
    "test_street_info['turn_tm'] = [d['turn'] if 'turn' in d else 0 for d in test_time_dict]\n",
    "train_street_info['roundabout_tm'] = [d['roundabout'] if 'roundabout' in d else 0 for d in train_time_dict]\n",
    "test_street_info['roundabout_tm'] = [d['roundabout'] if 'roundabout' in d else 0 for d in test_time_dict]\n",
    "train_street_info['roundabout_turn_tm'] = [d['roundabout turn'] if 'roudabout turn' in d else 0 for d in train_time_dict]\n",
    "test_street_info['roundabout_turn_tm'] = [d['roundabout turn'] if 'roundabout turn' in d else 0 for d in test_time_dict]\n",
    "\n",
    "train_street_info['arrive_ds'] = [d['arrive'] if 'arrive' in d else 0 for d in train_dist_dict]\n",
    "test_street_info['arrive_ds'] = [d['arrive'] if 'arrive' in d else 0 for d in test_dist_dict]\n",
    "train_street_info['depart_ds'] = [d['depart'] if 'depart' in d else 0 for d in train_dist_dict]\n",
    "test_street_info['depart_ds'] = [d['depart'] if 'depart' in d else 0 for d in test_dist_dict]\n",
    "train_street_info['end_of_road_ds'] = [d['end of road'] if 'end of road' in d else 0 for d in train_dist_dict]\n",
    "test_street_info['end_of_road_ds'] = [d['end of road'] if 'end of road' in d else 0 for d in test_dist_dict]\n",
    "train_street_info['new_name_ds'] = [d['new name'] if 'new name' in d else 0 for d in train_dist_dict]\n",
    "test_street_info['new_name_ds'] = [d['new name'] if 'new name' in d else 0 for d in test_dist_dict]\n",
    "train_street_info['rotary_ds'] = [d['rotary'] if 'rotary' in d else 0 for d in train_dist_dict]\n",
    "test_street_info['rotary_ds'] = [d['rotary'] if 'rotary' in d else 0 for d in test_dist_dict]\n",
    "train_street_info['merge_ds'] = [d['merge'] if 'merge' in d else 0 for d in train_dist_dict]\n",
    "test_street_info['merge_ds'] = [d['merge'] if 'merge' in d else 0 for d in test_dist_dict]\n",
    "train_street_info['continue_ds'] = [d['continue'] if 'continue' in d else 0 for d in train_dist_dict]\n",
    "test_street_info['continue_ds'] = [d['continue'] if 'continue' in d else 0 for d in test_dist_dict]\n",
    "train_street_info['onramp_ds'] = [d['on ramp'] if 'on ramp' in d else 0 for d in train_dist_dict]\n",
    "test_street_info['onramp_ds'] = [d['on ramp'] if 'on ramp' in d else 0 for d in test_dist_dict]\n",
    "train_street_info['offramp_ds'] = [d['off ramp'] if 'off ramp' in d else 0 for d in train_dist_dict]\n",
    "test_street_info['offramp_ds'] = [d['off ramp'] if 'off ramp' in d else 0 for d in test_dist_dict]\n",
    "train_street_info['fork_ds'] = [d['fork'] if 'fork' in d else 0 for d in train_dist_dict]\n",
    "test_street_info['fork_ds'] = [d['fork'] if 'fork' in d else 0 for d in test_dist_dict]\n",
    "train_street_info['turn_ds'] = [d['turn'] if 'turn' in d else 0 for d in train_dist_dict]\n",
    "test_street_info['turn_ds'] = [d['turn'] if 'turn' in d else 0 for d in test_dist_dict]\n",
    "train_street_info['roundabout_ds'] = [d['roundabout']if 'roundabout' in d else 0 for d in train_dist_dict]\n",
    "test_street_info['roundabout_ds'] = [d['roundabout'] if 'roudabout' in d else 0 for d in test_dist_dict]\n",
    "train_street_info['roundabout_turn_ds'] = [d['roundabout turn'] if 'roudabout turn' in d else 0 for d in train_dist_dict]\n",
    "test_street_info['roundabout_turn_ds'] = [d['roundabout turn'] if 'roundabout turn' in d else 0 for d in test_dist_dict]\n",
    "\n",
    "train_street_info['street_count'] = [len(x) for x in train_street_info['street_for_each_step'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "test_street_info['street_count'] = [len(x) for x in test_street_info['street_for_each_step'].apply(lambda x: x.split(\"|\")).values.tolist()]\n",
    "\n",
    "#train_street_info['start_eq_end'] = [train_street_info['starting_street'] == train_street_info['end_street']]\n",
    "#test_street_info['start_eq_end'] = [test_street_info['starting_street'] == test_street_info['end_street']]\n",
    "\n",
    "#usecols=['id', 'total_distance', 'total_travel_time', 'number_of_steps']\n",
    "dropcols=['starting_street','end_street','street_for_each_step','distance_per_step',\n",
    "          'travel_time_per_step','step_maneuvers','step_direction','step_location_list']\n",
    "trainusecols = [a for a in train_street_info.columns.tolist() if a not in dropcols]\n",
    "testusecols = [a for a in test_street_info.columns.tolist() if a not in dropcols]\n",
    "\n",
    "train = train.merge(train_street_info[trainusecols], how='left', on='id')\n",
    "test = test.merge(test_street_info[testusecols], how='left', on='id')\n",
    "train_street_info.head()\n",
    "#train_street_info\n",
    "#test_street_info\n",
    "#del test_dist_dict\n",
    "#del test_time_dict\n",
    "#del train_dist_dict\n",
    "#del train_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avg_speed_h' 'avg_speed_m' 'check_trip_duration' 'dropoff_datetime'\n",
      " 'log_trip_duration' 'trip_duration']\n"
     ]
    }
   ],
   "source": [
    "print(np.setdiff1d(train.columns, test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_street_info\n",
    "del test_street_info\n",
    "del test_dist_dict\n",
    "del test_time_dict\n",
    "del train_dist_dict\n",
    "del train_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avg_speed_h' 'avg_speed_m' 'check_trip_duration' 'dropoff_datetime'\n",
      " 'log_trip_duration' 'trip_duration']\n",
      "We have 106 features.\n",
      "Feature extraction time: 668 seconds\n"
     ]
    }
   ],
   "source": [
    "#feature_names = list(train.columns)\n",
    "print(np.setdiff1d(train.columns, test.columns))\n",
    "# do_not_use_for_training = ['id', 'log_trip_duration', 'pickup_datetime', 'dropoff_datetime', \n",
    "#                            'trip_duration', 'check_trip_duration','pickup_date', 'avg_speed_h', \n",
    "#                            'avg_speed_m', 'pickup_lat_bin', 'pickup_long_bin',\n",
    "#                            'center_lat_bin', 'center_long_bin', 'pickup_dt_bin', \n",
    "#                            'pickup_datetime_group']\n",
    "do_not_use_for_training = ['id', 'log_trip_duration', 'pickup_datetime', 'dropoff_datetime', \n",
    "                           'trip_duration', 'check_trip_duration','pickup_date', 'avg_speed_h', \n",
    "                           'avg_speed_m', 'pickup_lat_bin', 'pickup_long_bin',\n",
    "                           'center_lat_bin', 'center_long_bin', 'pickup_dt_bin', \n",
    "                           'pickup_datetime_group']\n",
    "\n",
    "feature_names = [f for f in train.columns if f not in do_not_use_for_training]\n",
    "#print(feature_names)\n",
    "print('We have %i features.' % len(feature_names))\n",
    "train[feature_names].count()\n",
    "y = np.log(train['trip_duration'].values + 1)\n",
    "#y = np.log(train['trip_duration'].loc[y_is_within_cut].values + 1)\n",
    "\n",
    "t1 = dt.datetime.now()\n",
    "print('Feature extraction time: %i seconds' % (t1 - t0).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>rotary_ds</th>\n",
       "      <th>merge_ds</th>\n",
       "      <th>continue_ds</th>\n",
       "      <th>onramp_ds</th>\n",
       "      <th>offramp_ds</th>\n",
       "      <th>fork_ds</th>\n",
       "      <th>turn_ds</th>\n",
       "      <th>roundabout_ds</th>\n",
       "      <th>roundabout_turn_ds</th>\n",
       "      <th>street_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>2016-03-14 17:32:30</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>576.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>885.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2377394</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-12 00:43:35</td>\n",
       "      <td>2016-06-12 00:54:38</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.980415</td>\n",
       "      <td>40.738564</td>\n",
       "      <td>-73.999481</td>\n",
       "      <td>40.731152</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>496.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3858529</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-19 11:35:24</td>\n",
       "      <td>2016-01-19 12:10:48</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7463.4</td>\n",
       "      <td>0</td>\n",
       "      <td>219.9</td>\n",
       "      <td>217.9</td>\n",
       "      <td>198.4</td>\n",
       "      <td>63.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3504673</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-06 19:32:31</td>\n",
       "      <td>2016-04-06 19:39:40</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.010040</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>379.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id2181028</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-26 13:30:55</td>\n",
       "      <td>2016-03-26 13:38:10</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.782520</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id     pickup_datetime    dropoff_datetime  \\\n",
       "0  id2875421          2 2016-03-14 17:24:55 2016-03-14 17:32:30   \n",
       "1  id2377394          1 2016-06-12 00:43:35 2016-06-12 00:54:38   \n",
       "2  id3858529          2 2016-01-19 11:35:24 2016-01-19 12:10:48   \n",
       "3  id3504673          2 2016-04-06 19:32:31 2016-04-06 19:39:40   \n",
       "4  id2181028          2 2016-03-26 13:30:55 2016-03-26 13:38:10   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.982155        40.767937         -73.964630   \n",
       "1                1        -73.980415        40.738564         -73.999481   \n",
       "2                1        -73.979027        40.763939         -74.005333   \n",
       "3                1        -74.010040        40.719971         -74.012268   \n",
       "4                1        -73.973053        40.793209         -73.972923   \n",
       "\n",
       "   dropoff_latitude  store_and_fwd_flag      ...       rotary_ds merge_ds  \\\n",
       "0         40.765602                   0      ...           576.4        0   \n",
       "1         40.731152                   0      ...               0        0   \n",
       "2         40.710087                   0      ...               0   7463.4   \n",
       "3         40.706718                   0      ...               0        0   \n",
       "4         40.782520                   0      ...               0        0   \n",
       "\n",
       "   continue_ds  onramp_ds  offramp_ds  fork_ds  turn_ds  roundabout_ds  \\\n",
       "0            0          0           0        0    885.6              0   \n",
       "1        139.1          0           0        0    496.1              0   \n",
       "2            0      219.9       217.9    198.4     63.8              0   \n",
       "3            0          0           0        0    379.9              0   \n",
       "4            0          0           0        0    158.3              0   \n",
       "\n",
       "   roundabout_turn_ds  street_count  \n",
       "0                 0.0           5.0  \n",
       "1                 0.0           6.0  \n",
       "2                 0.0          16.0  \n",
       "3                 0.0           4.0  \n",
       "4                 0.0           5.0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train = train.fillna(train.median())\n",
    "#test = test.fillna(test.median())\n",
    "# train['pickup_dt'] = (train['pickup_dt'] -train['pickup_dt'].mean())/train['pickup_dt'].std()\n",
    "# test['pickup_dt'] = (test['pickup_dt'] - test['pickup_dt'].mean())/test['pickup_dt'].std()\n",
    "\n",
    "# train['pickup_longitude'] = (train['pickup_longitude'] -train['pickup_longitude'].mean())/train['pickup_longitude'].std()\n",
    "# test['pickup_longitude'] = (test['pickup_longitude'] - test['pickup_longitude'].mean())/test['pickup_longitude'].std()\n",
    "# train['pickup_latitude'] = (train['pickup_latitude'] -train['pickup_latitude'].mean())/train['pickup_latitude'].std()\n",
    "# test['pickup_latitude'] = (test['pickup_latitude'] - test['pickup_latitude'].mean())/test['pickup_latitude'].std()\n",
    "# train['dropoff_longitude'] = (train['dropoff_longitude'] -train['dropoff_longitude'].mean())/train['dropoff_longitude'].std()\n",
    "# test['dropoff_longitude'] = (test['dropoff_longitude'] - test['dropoff_longitude'].mean())/test['dropoff_longitude'].std()\n",
    "# train['dropoff_latitude'] = (train['dropoff_latitude'] -train['dropoff_latitude'].mean())/train['dropoff_latitude'].std()\n",
    "# test['dropoff_latitude'] = (test['dropoff_latitude'] - test['dropoff_latitude'].mean())/test['dropoff_latitude'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr, Xv, ytr, yv = train_test_split(train[feature_names].values, y, test_size=0.02, random_state=1987)\n",
    "#Xtr, Xv, ytr, yv = train_test_split(train[feature_names].loc[y_is_within_cut,:].values, y, test_size=0.02, random_state=1987)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model,Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def fit(X,y,dims):\n",
    "    hidden_neurons = 128\n",
    "    bs = 32\n",
    "\n",
    "    model = Sequential()  \n",
    "    #model.add(Dense(hidden_neurons, batch_input_shape=(None, length_of_sequences, in_out_neurons), return_sequences=False))\n",
    "    #model.add(LSTM(hidden_neurons, input_dim=length_of_sequences, return_sequences=True))\n",
    "    model.add(Dense(64, activation='relu',input_dim=dims))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\")) \n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(32))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\")) \n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"linear\"))  \n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"nadam\")\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=1)\n",
    "    #model.load_weights(\"nn_model.h5\") \n",
    "    model.fit(X, y, batch_size=bs, epochs=5, validation_split=0.1, callbacks=[early_stopping])  \n",
    "    \n",
    "    #model.fit(X_train, y_train, batch_size=bs, nb_epoch=15, validation_data=(X_test, y_test), callbacks=[remote])     \n",
    "    model_checkpoint = ModelCheckpoint(\"nn_model.h5\", save_best_only=True, save_weights_only=True)\n",
    "    #predicted = model.predict(X) \n",
    "    #dataf =  pd.DataFrame(predicted[:1200])\n",
    "    #dataf.columns = [\"predict\"]\n",
    "    #dataf[\"input\"] = y_test[:1200]\n",
    "    #dataf.plot(figsize=(15, 5))\n",
    "\n",
    "    #score = model.evaluate(X_test.as_matrix(), y_test, batch_size=16)\n",
    "    #score = model.evaluate(X_test, y_test, batch_size=32)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unorderable types: float() >= str()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-4196449db5cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda2\\envs\\tf\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   2250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2251\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[1;32m-> 2252\u001b[1;33m                           out=out, **kwargs)\n\u001b[0m\u001b[0;32m   2253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\tf\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# small reductions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unorderable types: float() >= str()"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7b549e29ea0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrfr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtraTreesRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mrfr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\tf\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \"\"\"\n\u001b[0;32m    246\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 58\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "rfr = ExtraTreesRegressor(n_estimators=500, max_depth=6, n_jobs=14, random_state=123, verbose=0)\n",
    "rfr.fit(Xtr,ytr)\n",
    "y_pred = reg.predict(Xv)\n",
    "rmse = np.sqrt(mean_squared_error(yv, y_pred))\n",
    "print(\"RMSE: %.4f\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = fit(Xtr,ytr,len(feature_names))\n",
    "model.evaluate(Xv,yv,batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.485286\n",
      "Train until valid scores didn't improve in 30 rounds.\n",
      "[2]\tvalid_0's l2: 0.385495\n",
      "[3]\tvalid_0's l2: 0.318342\n",
      "[4]\tvalid_0's l2: 0.273454\n",
      "[5]\tvalid_0's l2: 0.243223\n",
      "[6]\tvalid_0's l2: 0.222842\n",
      "[7]\tvalid_0's l2: 0.208355\n",
      "[8]\tvalid_0's l2: 0.198122\n",
      "[9]\tvalid_0's l2: 0.190815\n",
      "[10]\tvalid_0's l2: 0.185654\n",
      "[11]\tvalid_0's l2: 0.181907\n",
      "[12]\tvalid_0's l2: 0.178946\n",
      "[13]\tvalid_0's l2: 0.177032\n",
      "[14]\tvalid_0's l2: 0.175535\n",
      "[15]\tvalid_0's l2: 0.174163\n",
      "[16]\tvalid_0's l2: 0.173138\n",
      "[17]\tvalid_0's l2: 0.171463\n",
      "[18]\tvalid_0's l2: 0.170797\n",
      "[19]\tvalid_0's l2: 0.169819\n",
      "[20]\tvalid_0's l2: 0.169412\n",
      "[21]\tvalid_0's l2: 0.168139\n",
      "[22]\tvalid_0's l2: 0.167572\n",
      "[23]\tvalid_0's l2: 0.167086\n",
      "[24]\tvalid_0's l2: 0.166722\n",
      "[25]\tvalid_0's l2: 0.166032\n",
      "[26]\tvalid_0's l2: 0.165554\n",
      "[27]\tvalid_0's l2: 0.165198\n",
      "[28]\tvalid_0's l2: 0.164875\n",
      "[29]\tvalid_0's l2: 0.164501\n",
      "[30]\tvalid_0's l2: 0.164058\n",
      "[31]\tvalid_0's l2: 0.163738\n",
      "[32]\tvalid_0's l2: 0.163421\n",
      "[33]\tvalid_0's l2: 0.16327\n",
      "[34]\tvalid_0's l2: 0.163062\n",
      "[35]\tvalid_0's l2: 0.162789\n",
      "[36]\tvalid_0's l2: 0.162433\n",
      "[37]\tvalid_0's l2: 0.162221\n",
      "[38]\tvalid_0's l2: 0.162009\n",
      "[39]\tvalid_0's l2: 0.161883\n",
      "[40]\tvalid_0's l2: 0.161716\n",
      "[41]\tvalid_0's l2: 0.161225\n",
      "[42]\tvalid_0's l2: 0.160977\n",
      "[43]\tvalid_0's l2: 0.160808\n",
      "[44]\tvalid_0's l2: 0.160559\n",
      "[45]\tvalid_0's l2: 0.160377\n",
      "[46]\tvalid_0's l2: 0.160207\n",
      "[47]\tvalid_0's l2: 0.160086\n",
      "[48]\tvalid_0's l2: 0.15992\n",
      "[49]\tvalid_0's l2: 0.159766\n",
      "[50]\tvalid_0's l2: 0.159671\n",
      "[51]\tvalid_0's l2: 0.159579\n",
      "[52]\tvalid_0's l2: 0.159501\n",
      "[53]\tvalid_0's l2: 0.159484\n",
      "[54]\tvalid_0's l2: 0.159274\n",
      "[55]\tvalid_0's l2: 0.159119\n",
      "[56]\tvalid_0's l2: 0.159016\n",
      "[57]\tvalid_0's l2: 0.158901\n",
      "[58]\tvalid_0's l2: 0.158804\n",
      "[59]\tvalid_0's l2: 0.158712\n",
      "[60]\tvalid_0's l2: 0.158569\n",
      "[61]\tvalid_0's l2: 0.15853\n",
      "[62]\tvalid_0's l2: 0.158304\n",
      "[63]\tvalid_0's l2: 0.158112\n",
      "[64]\tvalid_0's l2: 0.158015\n",
      "[65]\tvalid_0's l2: 0.157924\n",
      "[66]\tvalid_0's l2: 0.157897\n",
      "[67]\tvalid_0's l2: 0.157789\n",
      "[68]\tvalid_0's l2: 0.157613\n",
      "[69]\tvalid_0's l2: 0.157483\n",
      "[70]\tvalid_0's l2: 0.157438\n",
      "[71]\tvalid_0's l2: 0.157296\n",
      "[72]\tvalid_0's l2: 0.15722\n",
      "[73]\tvalid_0's l2: 0.157146\n",
      "[74]\tvalid_0's l2: 0.157029\n",
      "[75]\tvalid_0's l2: 0.156903\n",
      "[76]\tvalid_0's l2: 0.156767\n",
      "[77]\tvalid_0's l2: 0.156647\n",
      "[78]\tvalid_0's l2: 0.15653\n",
      "[79]\tvalid_0's l2: 0.156427\n",
      "[80]\tvalid_0's l2: 0.156287\n",
      "[81]\tvalid_0's l2: 0.156166\n",
      "[82]\tvalid_0's l2: 0.156165\n",
      "[83]\tvalid_0's l2: 0.156093\n",
      "[84]\tvalid_0's l2: 0.156026\n",
      "[85]\tvalid_0's l2: 0.15598\n",
      "[86]\tvalid_0's l2: 0.155926\n",
      "[87]\tvalid_0's l2: 0.155876\n",
      "[88]\tvalid_0's l2: 0.155736\n",
      "[89]\tvalid_0's l2: 0.155665\n",
      "[90]\tvalid_0's l2: 0.155589\n",
      "[91]\tvalid_0's l2: 0.15558\n",
      "[92]\tvalid_0's l2: 0.15554\n",
      "[93]\tvalid_0's l2: 0.155477\n",
      "[94]\tvalid_0's l2: 0.155398\n",
      "[95]\tvalid_0's l2: 0.155321\n",
      "[96]\tvalid_0's l2: 0.155211\n",
      "[97]\tvalid_0's l2: 0.155122\n",
      "[98]\tvalid_0's l2: 0.155126\n",
      "[99]\tvalid_0's l2: 0.155065\n",
      "[100]\tvalid_0's l2: 0.155081\n",
      "[101]\tvalid_0's l2: 0.155037\n",
      "[102]\tvalid_0's l2: 0.154963\n",
      "[103]\tvalid_0's l2: 0.154931\n",
      "[104]\tvalid_0's l2: 0.154817\n",
      "[105]\tvalid_0's l2: 0.154772\n",
      "[106]\tvalid_0's l2: 0.154717\n",
      "[107]\tvalid_0's l2: 0.154618\n",
      "[108]\tvalid_0's l2: 0.1546\n",
      "[109]\tvalid_0's l2: 0.154594\n",
      "[110]\tvalid_0's l2: 0.154541\n",
      "[111]\tvalid_0's l2: 0.154482\n",
      "[112]\tvalid_0's l2: 0.154424\n",
      "[113]\tvalid_0's l2: 0.15437\n",
      "[114]\tvalid_0's l2: 0.154313\n",
      "[115]\tvalid_0's l2: 0.154237\n",
      "[116]\tvalid_0's l2: 0.154196\n",
      "[117]\tvalid_0's l2: 0.154194\n",
      "[118]\tvalid_0's l2: 0.154104\n",
      "[119]\tvalid_0's l2: 0.153995\n",
      "[120]\tvalid_0's l2: 0.153931\n",
      "[121]\tvalid_0's l2: 0.153834\n",
      "[122]\tvalid_0's l2: 0.153864\n",
      "[123]\tvalid_0's l2: 0.153851\n",
      "[124]\tvalid_0's l2: 0.153806\n",
      "[125]\tvalid_0's l2: 0.15375\n",
      "[126]\tvalid_0's l2: 0.153717\n",
      "[127]\tvalid_0's l2: 0.153683\n",
      "[128]\tvalid_0's l2: 0.153672\n",
      "[129]\tvalid_0's l2: 0.153669\n",
      "[130]\tvalid_0's l2: 0.153683\n",
      "[131]\tvalid_0's l2: 0.153685\n",
      "[132]\tvalid_0's l2: 0.153657\n",
      "[133]\tvalid_0's l2: 0.153633\n",
      "[134]\tvalid_0's l2: 0.153596\n",
      "[135]\tvalid_0's l2: 0.153537\n",
      "[136]\tvalid_0's l2: 0.153503\n",
      "[137]\tvalid_0's l2: 0.15344\n",
      "[138]\tvalid_0's l2: 0.153365\n",
      "[139]\tvalid_0's l2: 0.153315\n",
      "[140]\tvalid_0's l2: 0.153248\n",
      "[141]\tvalid_0's l2: 0.153226\n",
      "[142]\tvalid_0's l2: 0.153268\n",
      "[143]\tvalid_0's l2: 0.15325\n",
      "[144]\tvalid_0's l2: 0.153192\n",
      "[145]\tvalid_0's l2: 0.153162\n",
      "[146]\tvalid_0's l2: 0.153085\n",
      "[147]\tvalid_0's l2: 0.153051\n",
      "[148]\tvalid_0's l2: 0.153028\n",
      "[149]\tvalid_0's l2: 0.152958\n",
      "[150]\tvalid_0's l2: 0.15294\n",
      "[151]\tvalid_0's l2: 0.152927\n",
      "[152]\tvalid_0's l2: 0.1529\n",
      "[153]\tvalid_0's l2: 0.152882\n",
      "[154]\tvalid_0's l2: 0.152898\n",
      "[155]\tvalid_0's l2: 0.152982\n",
      "[156]\tvalid_0's l2: 0.152953\n",
      "[157]\tvalid_0's l2: 0.152929\n",
      "[158]\tvalid_0's l2: 0.152918\n",
      "[159]\tvalid_0's l2: 0.152895\n",
      "[160]\tvalid_0's l2: 0.152841\n",
      "[161]\tvalid_0's l2: 0.152796\n",
      "[162]\tvalid_0's l2: 0.15275\n",
      "[163]\tvalid_0's l2: 0.152733\n",
      "[164]\tvalid_0's l2: 0.152755\n",
      "[165]\tvalid_0's l2: 0.152729\n",
      "[166]\tvalid_0's l2: 0.15268\n",
      "[167]\tvalid_0's l2: 0.152636\n",
      "[168]\tvalid_0's l2: 0.152604\n",
      "[169]\tvalid_0's l2: 0.152593\n",
      "[170]\tvalid_0's l2: 0.152584\n",
      "[171]\tvalid_0's l2: 0.15257\n",
      "[172]\tvalid_0's l2: 0.152513\n",
      "[173]\tvalid_0's l2: 0.15248\n",
      "[174]\tvalid_0's l2: 0.152458\n",
      "[175]\tvalid_0's l2: 0.152417\n",
      "[176]\tvalid_0's l2: 0.152386\n",
      "[177]\tvalid_0's l2: 0.152379\n",
      "[178]\tvalid_0's l2: 0.152351\n",
      "[179]\tvalid_0's l2: 0.152267\n",
      "[180]\tvalid_0's l2: 0.152219\n",
      "[181]\tvalid_0's l2: 0.152149\n",
      "[182]\tvalid_0's l2: 0.15215\n",
      "[183]\tvalid_0's l2: 0.152071\n",
      "[184]\tvalid_0's l2: 0.151968\n",
      "[185]\tvalid_0's l2: 0.15191\n",
      "[186]\tvalid_0's l2: 0.151892\n",
      "[187]\tvalid_0's l2: 0.151863\n",
      "[188]\tvalid_0's l2: 0.151839\n",
      "[189]\tvalid_0's l2: 0.151822\n",
      "[190]\tvalid_0's l2: 0.151817\n",
      "[191]\tvalid_0's l2: 0.151779\n",
      "[192]\tvalid_0's l2: 0.151762\n",
      "[193]\tvalid_0's l2: 0.151757\n",
      "[194]\tvalid_0's l2: 0.151715\n",
      "[195]\tvalid_0's l2: 0.151638\n",
      "[196]\tvalid_0's l2: 0.151682\n",
      "[197]\tvalid_0's l2: 0.151658\n",
      "[198]\tvalid_0's l2: 0.151636\n",
      "[199]\tvalid_0's l2: 0.151607\n",
      "[200]\tvalid_0's l2: 0.151587\n",
      "[201]\tvalid_0's l2: 0.151582\n",
      "[202]\tvalid_0's l2: 0.151544\n",
      "[203]\tvalid_0's l2: 0.151569\n",
      "[204]\tvalid_0's l2: 0.151515\n",
      "[205]\tvalid_0's l2: 0.151464\n",
      "[206]\tvalid_0's l2: 0.151421\n",
      "[207]\tvalid_0's l2: 0.151388\n",
      "[208]\tvalid_0's l2: 0.151343\n",
      "[209]\tvalid_0's l2: 0.151347\n",
      "[210]\tvalid_0's l2: 0.15133\n",
      "[211]\tvalid_0's l2: 0.151323\n",
      "[212]\tvalid_0's l2: 0.151327\n",
      "[213]\tvalid_0's l2: 0.151279\n",
      "[214]\tvalid_0's l2: 0.151267\n",
      "[215]\tvalid_0's l2: 0.151276\n",
      "[216]\tvalid_0's l2: 0.151217\n",
      "[217]\tvalid_0's l2: 0.151184\n",
      "[218]\tvalid_0's l2: 0.151158\n",
      "[219]\tvalid_0's l2: 0.15111\n",
      "[220]\tvalid_0's l2: 0.151093\n",
      "[221]\tvalid_0's l2: 0.151075\n",
      "[222]\tvalid_0's l2: 0.151063\n",
      "[223]\tvalid_0's l2: 0.151056\n",
      "[224]\tvalid_0's l2: 0.151015\n",
      "[225]\tvalid_0's l2: 0.150996\n",
      "[226]\tvalid_0's l2: 0.150965\n",
      "[227]\tvalid_0's l2: 0.150982\n",
      "[228]\tvalid_0's l2: 0.15096\n",
      "[229]\tvalid_0's l2: 0.150938\n",
      "[230]\tvalid_0's l2: 0.150906\n",
      "[231]\tvalid_0's l2: 0.150904\n",
      "[232]\tvalid_0's l2: 0.150838\n",
      "[233]\tvalid_0's l2: 0.15081\n",
      "[234]\tvalid_0's l2: 0.150817\n",
      "[235]\tvalid_0's l2: 0.150808\n",
      "[236]\tvalid_0's l2: 0.150769\n",
      "[237]\tvalid_0's l2: 0.150761\n",
      "[238]\tvalid_0's l2: 0.150713\n",
      "[239]\tvalid_0's l2: 0.150687\n",
      "[240]\tvalid_0's l2: 0.150677\n",
      "[241]\tvalid_0's l2: 0.150644\n",
      "[242]\tvalid_0's l2: 0.150652\n",
      "[243]\tvalid_0's l2: 0.150641\n",
      "[244]\tvalid_0's l2: 0.150633\n",
      "[245]\tvalid_0's l2: 0.150589\n",
      "[246]\tvalid_0's l2: 0.150528\n",
      "[247]\tvalid_0's l2: 0.150491\n",
      "[248]\tvalid_0's l2: 0.150443\n",
      "[249]\tvalid_0's l2: 0.150404\n",
      "[250]\tvalid_0's l2: 0.150378\n",
      "[251]\tvalid_0's l2: 0.150376\n",
      "[252]\tvalid_0's l2: 0.150365\n",
      "[253]\tvalid_0's l2: 0.150334\n",
      "[254]\tvalid_0's l2: 0.150324\n",
      "[255]\tvalid_0's l2: 0.150292\n",
      "[256]\tvalid_0's l2: 0.150286\n",
      "[257]\tvalid_0's l2: 0.150277\n",
      "[258]\tvalid_0's l2: 0.150257\n",
      "[259]\tvalid_0's l2: 0.150245\n",
      "[260]\tvalid_0's l2: 0.150181\n",
      "[261]\tvalid_0's l2: 0.150161\n",
      "[262]\tvalid_0's l2: 0.150133\n",
      "[263]\tvalid_0's l2: 0.150102\n",
      "[264]\tvalid_0's l2: 0.150034\n",
      "[265]\tvalid_0's l2: 0.150006\n",
      "[266]\tvalid_0's l2: 0.149985\n",
      "[267]\tvalid_0's l2: 0.149955\n",
      "[268]\tvalid_0's l2: 0.149947\n",
      "[269]\tvalid_0's l2: 0.149942\n",
      "[270]\tvalid_0's l2: 0.149901\n",
      "[271]\tvalid_0's l2: 0.149878\n",
      "[272]\tvalid_0's l2: 0.149871\n",
      "[273]\tvalid_0's l2: 0.149864\n",
      "[274]\tvalid_0's l2: 0.149888\n",
      "[275]\tvalid_0's l2: 0.14986\n",
      "[276]\tvalid_0's l2: 0.149861\n",
      "[277]\tvalid_0's l2: 0.149849\n",
      "[278]\tvalid_0's l2: 0.149844\n",
      "[279]\tvalid_0's l2: 0.149819\n",
      "[280]\tvalid_0's l2: 0.149792\n",
      "[281]\tvalid_0's l2: 0.149785\n",
      "[282]\tvalid_0's l2: 0.149781\n",
      "[283]\tvalid_0's l2: 0.149767\n",
      "[284]\tvalid_0's l2: 0.149811\n",
      "[285]\tvalid_0's l2: 0.149785\n",
      "[286]\tvalid_0's l2: 0.149731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[287]\tvalid_0's l2: 0.149699\n",
      "[288]\tvalid_0's l2: 0.149687\n",
      "[289]\tvalid_0's l2: 0.149687\n",
      "[290]\tvalid_0's l2: 0.149677\n",
      "[291]\tvalid_0's l2: 0.149658\n",
      "[292]\tvalid_0's l2: 0.149636\n",
      "[293]\tvalid_0's l2: 0.149622\n",
      "[294]\tvalid_0's l2: 0.149617\n",
      "[295]\tvalid_0's l2: 0.149602\n",
      "[296]\tvalid_0's l2: 0.149602\n",
      "[297]\tvalid_0's l2: 0.149602\n",
      "[298]\tvalid_0's l2: 0.1496\n",
      "[299]\tvalid_0's l2: 0.14959\n",
      "[300]\tvalid_0's l2: 0.149572\n",
      "[301]\tvalid_0's l2: 0.149557\n",
      "[302]\tvalid_0's l2: 0.149533\n",
      "[303]\tvalid_0's l2: 0.149519\n",
      "[304]\tvalid_0's l2: 0.149509\n",
      "[305]\tvalid_0's l2: 0.1495\n",
      "[306]\tvalid_0's l2: 0.149506\n",
      "[307]\tvalid_0's l2: 0.149503\n",
      "[308]\tvalid_0's l2: 0.149495\n",
      "[309]\tvalid_0's l2: 0.149455\n",
      "[310]\tvalid_0's l2: 0.149434\n",
      "[311]\tvalid_0's l2: 0.149417\n",
      "[312]\tvalid_0's l2: 0.14941\n",
      "[313]\tvalid_0's l2: 0.149349\n",
      "[314]\tvalid_0's l2: 0.149322\n",
      "[315]\tvalid_0's l2: 0.14928\n",
      "[316]\tvalid_0's l2: 0.149286\n",
      "[317]\tvalid_0's l2: 0.149272\n",
      "[318]\tvalid_0's l2: 0.149262\n",
      "[319]\tvalid_0's l2: 0.149225\n",
      "[320]\tvalid_0's l2: 0.149238\n",
      "[321]\tvalid_0's l2: 0.149214\n",
      "[322]\tvalid_0's l2: 0.149197\n",
      "[323]\tvalid_0's l2: 0.149184\n",
      "[324]\tvalid_0's l2: 0.149162\n",
      "[325]\tvalid_0's l2: 0.149151\n",
      "[326]\tvalid_0's l2: 0.149143\n",
      "[327]\tvalid_0's l2: 0.149114\n",
      "[328]\tvalid_0's l2: 0.149152\n",
      "[329]\tvalid_0's l2: 0.149132\n",
      "[330]\tvalid_0's l2: 0.1491\n",
      "[331]\tvalid_0's l2: 0.149093\n",
      "[332]\tvalid_0's l2: 0.14909\n",
      "[333]\tvalid_0's l2: 0.14904\n",
      "[334]\tvalid_0's l2: 0.149033\n",
      "[335]\tvalid_0's l2: 0.149031\n",
      "[336]\tvalid_0's l2: 0.149032\n",
      "[337]\tvalid_0's l2: 0.14905\n",
      "[338]\tvalid_0's l2: 0.149038\n",
      "[339]\tvalid_0's l2: 0.149027\n",
      "[340]\tvalid_0's l2: 0.149045\n",
      "[341]\tvalid_0's l2: 0.149026\n",
      "[342]\tvalid_0's l2: 0.149035\n",
      "[343]\tvalid_0's l2: 0.148995\n",
      "[344]\tvalid_0's l2: 0.14897\n",
      "[345]\tvalid_0's l2: 0.148983\n",
      "[346]\tvalid_0's l2: 0.148938\n",
      "[347]\tvalid_0's l2: 0.148912\n",
      "[348]\tvalid_0's l2: 0.148906\n",
      "[349]\tvalid_0's l2: 0.148879\n",
      "[350]\tvalid_0's l2: 0.148867\n",
      "[351]\tvalid_0's l2: 0.148876\n",
      "[352]\tvalid_0's l2: 0.148865\n",
      "[353]\tvalid_0's l2: 0.148867\n",
      "[354]\tvalid_0's l2: 0.148855\n",
      "[355]\tvalid_0's l2: 0.148839\n",
      "[356]\tvalid_0's l2: 0.148831\n",
      "[357]\tvalid_0's l2: 0.148805\n",
      "[358]\tvalid_0's l2: 0.148825\n",
      "[359]\tvalid_0's l2: 0.148827\n",
      "[360]\tvalid_0's l2: 0.148806\n",
      "[361]\tvalid_0's l2: 0.1488\n",
      "[362]\tvalid_0's l2: 0.148801\n",
      "[363]\tvalid_0's l2: 0.148786\n",
      "[364]\tvalid_0's l2: 0.148726\n",
      "[365]\tvalid_0's l2: 0.148713\n",
      "[366]\tvalid_0's l2: 0.148693\n",
      "[367]\tvalid_0's l2: 0.148686\n",
      "[368]\tvalid_0's l2: 0.148647\n",
      "[369]\tvalid_0's l2: 0.14863\n",
      "[370]\tvalid_0's l2: 0.148623\n",
      "[371]\tvalid_0's l2: 0.148625\n",
      "[372]\tvalid_0's l2: 0.148612\n",
      "[373]\tvalid_0's l2: 0.148588\n",
      "[374]\tvalid_0's l2: 0.148573\n",
      "[375]\tvalid_0's l2: 0.148574\n",
      "[376]\tvalid_0's l2: 0.148562\n",
      "[377]\tvalid_0's l2: 0.148513\n",
      "[378]\tvalid_0's l2: 0.148472\n",
      "[379]\tvalid_0's l2: 0.148456\n",
      "[380]\tvalid_0's l2: 0.148455\n",
      "[381]\tvalid_0's l2: 0.148423\n",
      "[382]\tvalid_0's l2: 0.148397\n",
      "[383]\tvalid_0's l2: 0.148387\n",
      "[384]\tvalid_0's l2: 0.148374\n",
      "[385]\tvalid_0's l2: 0.148375\n",
      "[386]\tvalid_0's l2: 0.148345\n",
      "[387]\tvalid_0's l2: 0.148339\n",
      "[388]\tvalid_0's l2: 0.148339\n",
      "[389]\tvalid_0's l2: 0.148335\n",
      "[390]\tvalid_0's l2: 0.14829\n",
      "[391]\tvalid_0's l2: 0.148211\n",
      "[392]\tvalid_0's l2: 0.148203\n",
      "[393]\tvalid_0's l2: 0.148192\n",
      "[394]\tvalid_0's l2: 0.148194\n",
      "[395]\tvalid_0's l2: 0.148165\n",
      "[396]\tvalid_0's l2: 0.148179\n",
      "[397]\tvalid_0's l2: 0.148178\n",
      "[398]\tvalid_0's l2: 0.148156\n",
      "[399]\tvalid_0's l2: 0.148133\n",
      "[400]\tvalid_0's l2: 0.148123\n",
      "[401]\tvalid_0's l2: 0.148243\n",
      "[402]\tvalid_0's l2: 0.148219\n",
      "[403]\tvalid_0's l2: 0.148225\n",
      "[404]\tvalid_0's l2: 0.148162\n",
      "[405]\tvalid_0's l2: 0.148145\n",
      "[406]\tvalid_0's l2: 0.148091\n",
      "[407]\tvalid_0's l2: 0.148066\n",
      "[408]\tvalid_0's l2: 0.147998\n",
      "[409]\tvalid_0's l2: 0.147973\n",
      "[410]\tvalid_0's l2: 0.147962\n",
      "[411]\tvalid_0's l2: 0.147986\n",
      "[412]\tvalid_0's l2: 0.148031\n",
      "[413]\tvalid_0's l2: 0.148035\n",
      "[414]\tvalid_0's l2: 0.148025\n",
      "[415]\tvalid_0's l2: 0.14801\n",
      "[416]\tvalid_0's l2: 0.148003\n",
      "[417]\tvalid_0's l2: 0.147972\n",
      "[418]\tvalid_0's l2: 0.14794\n",
      "[419]\tvalid_0's l2: 0.147939\n",
      "[420]\tvalid_0's l2: 0.147935\n",
      "[421]\tvalid_0's l2: 0.147921\n",
      "[422]\tvalid_0's l2: 0.147912\n",
      "[423]\tvalid_0's l2: 0.147897\n",
      "[424]\tvalid_0's l2: 0.1479\n",
      "[425]\tvalid_0's l2: 0.147873\n",
      "[426]\tvalid_0's l2: 0.147822\n",
      "[427]\tvalid_0's l2: 0.147814\n",
      "[428]\tvalid_0's l2: 0.147786\n",
      "[429]\tvalid_0's l2: 0.147779\n",
      "[430]\tvalid_0's l2: 0.147757\n",
      "[431]\tvalid_0's l2: 0.147745\n",
      "[432]\tvalid_0's l2: 0.147745\n",
      "[433]\tvalid_0's l2: 0.147743\n",
      "[434]\tvalid_0's l2: 0.147726\n",
      "[435]\tvalid_0's l2: 0.147718\n",
      "[436]\tvalid_0's l2: 0.147709\n",
      "[437]\tvalid_0's l2: 0.1477\n",
      "[438]\tvalid_0's l2: 0.147714\n",
      "[439]\tvalid_0's l2: 0.147697\n",
      "[440]\tvalid_0's l2: 0.147662\n",
      "[441]\tvalid_0's l2: 0.147666\n",
      "[442]\tvalid_0's l2: 0.147659\n",
      "[443]\tvalid_0's l2: 0.147625\n",
      "[444]\tvalid_0's l2: 0.14763\n",
      "[445]\tvalid_0's l2: 0.147636\n",
      "[446]\tvalid_0's l2: 0.147638\n",
      "[447]\tvalid_0's l2: 0.147624\n",
      "[448]\tvalid_0's l2: 0.147615\n",
      "[449]\tvalid_0's l2: 0.147596\n",
      "[450]\tvalid_0's l2: 0.147544\n",
      "[451]\tvalid_0's l2: 0.147557\n",
      "[452]\tvalid_0's l2: 0.147555\n",
      "[453]\tvalid_0's l2: 0.147558\n",
      "[454]\tvalid_0's l2: 0.147544\n",
      "[455]\tvalid_0's l2: 0.147526\n",
      "[456]\tvalid_0's l2: 0.147527\n",
      "[457]\tvalid_0's l2: 0.14751\n",
      "[458]\tvalid_0's l2: 0.147525\n",
      "[459]\tvalid_0's l2: 0.147525\n",
      "[460]\tvalid_0's l2: 0.147512\n",
      "[461]\tvalid_0's l2: 0.147504\n",
      "[462]\tvalid_0's l2: 0.147504\n",
      "[463]\tvalid_0's l2: 0.147447\n",
      "[464]\tvalid_0's l2: 0.147433\n",
      "[465]\tvalid_0's l2: 0.147424\n",
      "[466]\tvalid_0's l2: 0.14742\n",
      "[467]\tvalid_0's l2: 0.147436\n",
      "[468]\tvalid_0's l2: 0.147428\n",
      "[469]\tvalid_0's l2: 0.14741\n",
      "[470]\tvalid_0's l2: 0.147394\n",
      "[471]\tvalid_0's l2: 0.147417\n",
      "[472]\tvalid_0's l2: 0.147431\n",
      "[473]\tvalid_0's l2: 0.147453\n",
      "[474]\tvalid_0's l2: 0.147453\n",
      "[475]\tvalid_0's l2: 0.147453\n",
      "[476]\tvalid_0's l2: 0.147441\n",
      "[477]\tvalid_0's l2: 0.147432\n",
      "[478]\tvalid_0's l2: 0.147424\n",
      "[479]\tvalid_0's l2: 0.147415\n",
      "[480]\tvalid_0's l2: 0.147422\n",
      "[481]\tvalid_0's l2: 0.147425\n",
      "[482]\tvalid_0's l2: 0.147419\n",
      "[483]\tvalid_0's l2: 0.147383\n",
      "[484]\tvalid_0's l2: 0.147374\n",
      "[485]\tvalid_0's l2: 0.147397\n",
      "[486]\tvalid_0's l2: 0.1474\n",
      "[487]\tvalid_0's l2: 0.147383\n",
      "[488]\tvalid_0's l2: 0.147372\n",
      "[489]\tvalid_0's l2: 0.147368\n",
      "[490]\tvalid_0's l2: 0.147365\n",
      "[491]\tvalid_0's l2: 0.147369\n",
      "[492]\tvalid_0's l2: 0.147386\n",
      "[493]\tvalid_0's l2: 0.14737\n",
      "[494]\tvalid_0's l2: 0.147344\n",
      "[495]\tvalid_0's l2: 0.147322\n",
      "[496]\tvalid_0's l2: 0.147301\n",
      "[497]\tvalid_0's l2: 0.147299\n",
      "[498]\tvalid_0's l2: 0.147291\n",
      "[499]\tvalid_0's l2: 0.147277\n",
      "[500]\tvalid_0's l2: 0.147272\n",
      "[501]\tvalid_0's l2: 0.147267\n",
      "[502]\tvalid_0's l2: 0.147264\n",
      "[503]\tvalid_0's l2: 0.147281\n",
      "[504]\tvalid_0's l2: 0.14728\n",
      "[505]\tvalid_0's l2: 0.147262\n",
      "[506]\tvalid_0's l2: 0.147275\n",
      "[507]\tvalid_0's l2: 0.147271\n",
      "[508]\tvalid_0's l2: 0.147246\n",
      "[509]\tvalid_0's l2: 0.147197\n",
      "[510]\tvalid_0's l2: 0.147199\n",
      "[511]\tvalid_0's l2: 0.147188\n",
      "[512]\tvalid_0's l2: 0.147187\n",
      "[513]\tvalid_0's l2: 0.147185\n",
      "[514]\tvalid_0's l2: 0.147181\n",
      "[515]\tvalid_0's l2: 0.147172\n",
      "[516]\tvalid_0's l2: 0.147175\n",
      "[517]\tvalid_0's l2: 0.1472\n",
      "[518]\tvalid_0's l2: 0.147206\n",
      "[519]\tvalid_0's l2: 0.147215\n",
      "[520]\tvalid_0's l2: 0.147212\n",
      "[521]\tvalid_0's l2: 0.147206\n",
      "[522]\tvalid_0's l2: 0.147167\n",
      "[523]\tvalid_0's l2: 0.147173\n",
      "[524]\tvalid_0's l2: 0.147177\n",
      "[525]\tvalid_0's l2: 0.147126\n",
      "[526]\tvalid_0's l2: 0.14713\n",
      "[527]\tvalid_0's l2: 0.14711\n",
      "[528]\tvalid_0's l2: 0.147116\n",
      "[529]\tvalid_0's l2: 0.147093\n",
      "[530]\tvalid_0's l2: 0.147076\n",
      "[531]\tvalid_0's l2: 0.147083\n",
      "[532]\tvalid_0's l2: 0.147057\n",
      "[533]\tvalid_0's l2: 0.147038\n",
      "[534]\tvalid_0's l2: 0.147065\n",
      "[535]\tvalid_0's l2: 0.147058\n",
      "[536]\tvalid_0's l2: 0.147052\n",
      "[537]\tvalid_0's l2: 0.147029\n",
      "[538]\tvalid_0's l2: 0.147026\n",
      "[539]\tvalid_0's l2: 0.146989\n",
      "[540]\tvalid_0's l2: 0.147\n",
      "[541]\tvalid_0's l2: 0.147011\n",
      "[542]\tvalid_0's l2: 0.146998\n",
      "[543]\tvalid_0's l2: 0.146987\n",
      "[544]\tvalid_0's l2: 0.146978\n",
      "[545]\tvalid_0's l2: 0.14697\n",
      "[546]\tvalid_0's l2: 0.146975\n",
      "[547]\tvalid_0's l2: 0.146963\n",
      "[548]\tvalid_0's l2: 0.146949\n",
      "[549]\tvalid_0's l2: 0.146933\n",
      "[550]\tvalid_0's l2: 0.146919\n",
      "[551]\tvalid_0's l2: 0.146926\n",
      "[552]\tvalid_0's l2: 0.146912\n",
      "[553]\tvalid_0's l2: 0.146928\n",
      "[554]\tvalid_0's l2: 0.146896\n",
      "[555]\tvalid_0's l2: 0.146871\n",
      "[556]\tvalid_0's l2: 0.146834\n",
      "[557]\tvalid_0's l2: 0.146844\n",
      "[558]\tvalid_0's l2: 0.146816\n",
      "[559]\tvalid_0's l2: 0.146837\n",
      "[560]\tvalid_0's l2: 0.146816\n",
      "[561]\tvalid_0's l2: 0.146783\n",
      "[562]\tvalid_0's l2: 0.14676\n",
      "[563]\tvalid_0's l2: 0.146763\n",
      "[564]\tvalid_0's l2: 0.146755\n",
      "[565]\tvalid_0's l2: 0.146738\n",
      "[566]\tvalid_0's l2: 0.146719\n",
      "[567]\tvalid_0's l2: 0.146714\n",
      "[568]\tvalid_0's l2: 0.146696\n",
      "[569]\tvalid_0's l2: 0.146687\n",
      "[570]\tvalid_0's l2: 0.1467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[571]\tvalid_0's l2: 0.146692\n",
      "[572]\tvalid_0's l2: 0.146698\n",
      "[573]\tvalid_0's l2: 0.146693\n",
      "[574]\tvalid_0's l2: 0.146686\n",
      "[575]\tvalid_0's l2: 0.146649\n",
      "[576]\tvalid_0's l2: 0.146656\n",
      "[577]\tvalid_0's l2: 0.146685\n",
      "[578]\tvalid_0's l2: 0.146692\n",
      "[579]\tvalid_0's l2: 0.146688\n",
      "[580]\tvalid_0's l2: 0.146667\n",
      "[581]\tvalid_0's l2: 0.146661\n",
      "[582]\tvalid_0's l2: 0.146674\n",
      "[583]\tvalid_0's l2: 0.146648\n",
      "[584]\tvalid_0's l2: 0.146643\n",
      "[585]\tvalid_0's l2: 0.146664\n",
      "[586]\tvalid_0's l2: 0.146688\n",
      "[587]\tvalid_0's l2: 0.146655\n",
      "[588]\tvalid_0's l2: 0.146657\n",
      "[589]\tvalid_0's l2: 0.146652\n",
      "[590]\tvalid_0's l2: 0.146621\n",
      "[591]\tvalid_0's l2: 0.146602\n",
      "[592]\tvalid_0's l2: 0.146596\n",
      "[593]\tvalid_0's l2: 0.146588\n",
      "[594]\tvalid_0's l2: 0.146608\n",
      "[595]\tvalid_0's l2: 0.146621\n",
      "[596]\tvalid_0's l2: 0.146623\n",
      "[597]\tvalid_0's l2: 0.146606\n",
      "[598]\tvalid_0's l2: 0.146589\n",
      "[599]\tvalid_0's l2: 0.146629\n",
      "[600]\tvalid_0's l2: 0.14662\n",
      "[601]\tvalid_0's l2: 0.146604\n",
      "[602]\tvalid_0's l2: 0.146607\n",
      "[603]\tvalid_0's l2: 0.146605\n",
      "[604]\tvalid_0's l2: 0.146605\n",
      "[605]\tvalid_0's l2: 0.146601\n",
      "[606]\tvalid_0's l2: 0.146589\n",
      "[607]\tvalid_0's l2: 0.146587\n",
      "[608]\tvalid_0's l2: 0.146571\n",
      "[609]\tvalid_0's l2: 0.146568\n",
      "[610]\tvalid_0's l2: 0.146557\n",
      "[611]\tvalid_0's l2: 0.146562\n",
      "[612]\tvalid_0's l2: 0.146544\n",
      "[613]\tvalid_0's l2: 0.146576\n",
      "[614]\tvalid_0's l2: 0.146547\n",
      "[615]\tvalid_0's l2: 0.146544\n",
      "[616]\tvalid_0's l2: 0.146534\n",
      "[617]\tvalid_0's l2: 0.146524\n",
      "[618]\tvalid_0's l2: 0.146507\n",
      "[619]\tvalid_0's l2: 0.14653\n",
      "[620]\tvalid_0's l2: 0.146525\n",
      "[621]\tvalid_0's l2: 0.146524\n",
      "[622]\tvalid_0's l2: 0.146531\n",
      "[623]\tvalid_0's l2: 0.146515\n",
      "[624]\tvalid_0's l2: 0.146479\n",
      "[625]\tvalid_0's l2: 0.146437\n",
      "[626]\tvalid_0's l2: 0.146441\n",
      "[627]\tvalid_0's l2: 0.146431\n",
      "[628]\tvalid_0's l2: 0.146413\n",
      "[629]\tvalid_0's l2: 0.146443\n",
      "[630]\tvalid_0's l2: 0.146427\n",
      "[631]\tvalid_0's l2: 0.146411\n",
      "[632]\tvalid_0's l2: 0.14641\n",
      "[633]\tvalid_0's l2: 0.146408\n",
      "[634]\tvalid_0's l2: 0.146403\n",
      "[635]\tvalid_0's l2: 0.146404\n",
      "[636]\tvalid_0's l2: 0.146404\n",
      "[637]\tvalid_0's l2: 0.146409\n",
      "[638]\tvalid_0's l2: 0.146366\n",
      "[639]\tvalid_0's l2: 0.146357\n",
      "[640]\tvalid_0's l2: 0.146336\n",
      "[641]\tvalid_0's l2: 0.14633\n",
      "[642]\tvalid_0's l2: 0.146296\n",
      "[643]\tvalid_0's l2: 0.146294\n",
      "[644]\tvalid_0's l2: 0.1463\n",
      "[645]\tvalid_0's l2: 0.146299\n",
      "[646]\tvalid_0's l2: 0.146284\n",
      "[647]\tvalid_0's l2: 0.146282\n",
      "[648]\tvalid_0's l2: 0.14626\n",
      "[649]\tvalid_0's l2: 0.146233\n",
      "[650]\tvalid_0's l2: 0.146227\n",
      "[651]\tvalid_0's l2: 0.146224\n",
      "[652]\tvalid_0's l2: 0.146216\n",
      "[653]\tvalid_0's l2: 0.146208\n",
      "[654]\tvalid_0's l2: 0.146212\n",
      "[655]\tvalid_0's l2: 0.146219\n",
      "[656]\tvalid_0's l2: 0.146215\n",
      "[657]\tvalid_0's l2: 0.146207\n",
      "[658]\tvalid_0's l2: 0.146194\n",
      "[659]\tvalid_0's l2: 0.146191\n",
      "[660]\tvalid_0's l2: 0.146234\n",
      "[661]\tvalid_0's l2: 0.146233\n",
      "[662]\tvalid_0's l2: 0.146233\n",
      "[663]\tvalid_0's l2: 0.14622\n",
      "[664]\tvalid_0's l2: 0.14624\n",
      "[665]\tvalid_0's l2: 0.146215\n",
      "[666]\tvalid_0's l2: 0.146226\n",
      "[667]\tvalid_0's l2: 0.146211\n",
      "[668]\tvalid_0's l2: 0.146205\n",
      "[669]\tvalid_0's l2: 0.146198\n",
      "[670]\tvalid_0's l2: 0.14619\n",
      "[671]\tvalid_0's l2: 0.146171\n",
      "[672]\tvalid_0's l2: 0.146147\n",
      "[673]\tvalid_0's l2: 0.146143\n",
      "[674]\tvalid_0's l2: 0.146132\n",
      "[675]\tvalid_0's l2: 0.146126\n",
      "[676]\tvalid_0's l2: 0.146106\n",
      "[677]\tvalid_0's l2: 0.146109\n",
      "[678]\tvalid_0's l2: 0.146094\n",
      "[679]\tvalid_0's l2: 0.146061\n",
      "[680]\tvalid_0's l2: 0.146035\n",
      "[681]\tvalid_0's l2: 0.146023\n",
      "[682]\tvalid_0's l2: 0.145959\n",
      "[683]\tvalid_0's l2: 0.145938\n",
      "[684]\tvalid_0's l2: 0.145937\n",
      "[685]\tvalid_0's l2: 0.145924\n",
      "[686]\tvalid_0's l2: 0.145924\n",
      "[687]\tvalid_0's l2: 0.145921\n",
      "[688]\tvalid_0's l2: 0.145902\n",
      "[689]\tvalid_0's l2: 0.145899\n",
      "[690]\tvalid_0's l2: 0.145895\n",
      "[691]\tvalid_0's l2: 0.145874\n",
      "[692]\tvalid_0's l2: 0.14587\n",
      "[693]\tvalid_0's l2: 0.145869\n",
      "[694]\tvalid_0's l2: 0.145854\n",
      "[695]\tvalid_0's l2: 0.145837\n",
      "[696]\tvalid_0's l2: 0.145817\n",
      "[697]\tvalid_0's l2: 0.145796\n",
      "[698]\tvalid_0's l2: 0.145761\n",
      "[699]\tvalid_0's l2: 0.145756\n",
      "[700]\tvalid_0's l2: 0.145733\n",
      "[701]\tvalid_0's l2: 0.145724\n",
      "[702]\tvalid_0's l2: 0.145712\n",
      "[703]\tvalid_0's l2: 0.145701\n",
      "[704]\tvalid_0's l2: 0.145681\n",
      "[705]\tvalid_0's l2: 0.145684\n",
      "[706]\tvalid_0's l2: 0.145697\n",
      "[707]\tvalid_0's l2: 0.145712\n",
      "[708]\tvalid_0's l2: 0.145704\n",
      "[709]\tvalid_0's l2: 0.145684\n",
      "[710]\tvalid_0's l2: 0.145661\n",
      "[711]\tvalid_0's l2: 0.145654\n",
      "[712]\tvalid_0's l2: 0.145645\n",
      "[713]\tvalid_0's l2: 0.14564\n",
      "[714]\tvalid_0's l2: 0.145654\n",
      "[715]\tvalid_0's l2: 0.145657\n",
      "[716]\tvalid_0's l2: 0.14565\n",
      "[717]\tvalid_0's l2: 0.145642\n",
      "[718]\tvalid_0's l2: 0.145639\n",
      "[719]\tvalid_0's l2: 0.145667\n",
      "[720]\tvalid_0's l2: 0.145693\n",
      "[721]\tvalid_0's l2: 0.14573\n",
      "[722]\tvalid_0's l2: 0.145733\n",
      "[723]\tvalid_0's l2: 0.145716\n",
      "[724]\tvalid_0's l2: 0.145701\n",
      "[725]\tvalid_0's l2: 0.145712\n",
      "[726]\tvalid_0's l2: 0.145706\n",
      "[727]\tvalid_0's l2: 0.145707\n",
      "[728]\tvalid_0's l2: 0.145703\n",
      "[729]\tvalid_0's l2: 0.145685\n",
      "[730]\tvalid_0's l2: 0.145664\n",
      "[731]\tvalid_0's l2: 0.145664\n",
      "[732]\tvalid_0's l2: 0.145663\n",
      "[733]\tvalid_0's l2: 0.145662\n",
      "[734]\tvalid_0's l2: 0.145646\n",
      "[735]\tvalid_0's l2: 0.145631\n",
      "[736]\tvalid_0's l2: 0.145672\n",
      "[737]\tvalid_0's l2: 0.14567\n",
      "[738]\tvalid_0's l2: 0.145672\n",
      "[739]\tvalid_0's l2: 0.145666\n",
      "[740]\tvalid_0's l2: 0.145651\n",
      "[741]\tvalid_0's l2: 0.145627\n",
      "[742]\tvalid_0's l2: 0.145614\n",
      "[743]\tvalid_0's l2: 0.145604\n",
      "[744]\tvalid_0's l2: 0.145584\n",
      "[745]\tvalid_0's l2: 0.14559\n",
      "[746]\tvalid_0's l2: 0.145582\n",
      "[747]\tvalid_0's l2: 0.145572\n",
      "[748]\tvalid_0's l2: 0.145573\n",
      "[749]\tvalid_0's l2: 0.145569\n",
      "[750]\tvalid_0's l2: 0.145577\n",
      "[751]\tvalid_0's l2: 0.145582\n",
      "[752]\tvalid_0's l2: 0.145585\n",
      "[753]\tvalid_0's l2: 0.145578\n",
      "[754]\tvalid_0's l2: 0.145574\n",
      "[755]\tvalid_0's l2: 0.145567\n",
      "[756]\tvalid_0's l2: 0.145573\n",
      "[757]\tvalid_0's l2: 0.145566\n",
      "[758]\tvalid_0's l2: 0.145573\n",
      "[759]\tvalid_0's l2: 0.145553\n",
      "[760]\tvalid_0's l2: 0.14559\n",
      "[761]\tvalid_0's l2: 0.145586\n",
      "[762]\tvalid_0's l2: 0.145581\n",
      "[763]\tvalid_0's l2: 0.145578\n",
      "[764]\tvalid_0's l2: 0.14558\n",
      "[765]\tvalid_0's l2: 0.145575\n",
      "[766]\tvalid_0's l2: 0.14556\n",
      "[767]\tvalid_0's l2: 0.145541\n",
      "[768]\tvalid_0's l2: 0.145516\n",
      "[769]\tvalid_0's l2: 0.145503\n",
      "[770]\tvalid_0's l2: 0.145503\n",
      "[771]\tvalid_0's l2: 0.145488\n",
      "[772]\tvalid_0's l2: 0.14549\n",
      "[773]\tvalid_0's l2: 0.14549\n",
      "[774]\tvalid_0's l2: 0.145466\n",
      "[775]\tvalid_0's l2: 0.145467\n",
      "[776]\tvalid_0's l2: 0.145472\n",
      "[777]\tvalid_0's l2: 0.145491\n",
      "[778]\tvalid_0's l2: 0.145494\n",
      "[779]\tvalid_0's l2: 0.145468\n",
      "[780]\tvalid_0's l2: 0.14547\n",
      "[781]\tvalid_0's l2: 0.145454\n",
      "[782]\tvalid_0's l2: 0.145431\n",
      "[783]\tvalid_0's l2: 0.145452\n",
      "[784]\tvalid_0's l2: 0.145431\n",
      "[785]\tvalid_0's l2: 0.145437\n",
      "[786]\tvalid_0's l2: 0.145436\n",
      "[787]\tvalid_0's l2: 0.145464\n",
      "[788]\tvalid_0's l2: 0.145464\n",
      "[789]\tvalid_0's l2: 0.145467\n",
      "[790]\tvalid_0's l2: 0.145436\n",
      "[791]\tvalid_0's l2: 0.145427\n",
      "[792]\tvalid_0's l2: 0.145427\n",
      "[793]\tvalid_0's l2: 0.145428\n",
      "[794]\tvalid_0's l2: 0.145429\n",
      "[795]\tvalid_0's l2: 0.145427\n",
      "[796]\tvalid_0's l2: 0.145407\n",
      "[797]\tvalid_0's l2: 0.145428\n",
      "[798]\tvalid_0's l2: 0.145424\n",
      "[799]\tvalid_0's l2: 0.145444\n",
      "[800]\tvalid_0's l2: 0.14541\n",
      "[801]\tvalid_0's l2: 0.145381\n",
      "[802]\tvalid_0's l2: 0.145367\n",
      "[803]\tvalid_0's l2: 0.145367\n",
      "[804]\tvalid_0's l2: 0.145356\n",
      "[805]\tvalid_0's l2: 0.145357\n",
      "[806]\tvalid_0's l2: 0.145357\n",
      "[807]\tvalid_0's l2: 0.145357\n",
      "[808]\tvalid_0's l2: 0.14535\n",
      "[809]\tvalid_0's l2: 0.145347\n",
      "[810]\tvalid_0's l2: 0.145336\n",
      "[811]\tvalid_0's l2: 0.14533\n",
      "[812]\tvalid_0's l2: 0.145319\n",
      "[813]\tvalid_0's l2: 0.145309\n",
      "[814]\tvalid_0's l2: 0.145303\n",
      "[815]\tvalid_0's l2: 0.145304\n",
      "[816]\tvalid_0's l2: 0.145318\n",
      "[817]\tvalid_0's l2: 0.145321\n",
      "[818]\tvalid_0's l2: 0.14534\n",
      "[819]\tvalid_0's l2: 0.145338\n",
      "[820]\tvalid_0's l2: 0.145359\n",
      "[821]\tvalid_0's l2: 0.145358\n",
      "[822]\tvalid_0's l2: 0.145333\n",
      "[823]\tvalid_0's l2: 0.145339\n",
      "[824]\tvalid_0's l2: 0.145338\n",
      "[825]\tvalid_0's l2: 0.145322\n",
      "[826]\tvalid_0's l2: 0.145304\n",
      "[827]\tvalid_0's l2: 0.1453\n",
      "[828]\tvalid_0's l2: 0.145298\n",
      "[829]\tvalid_0's l2: 0.145278\n",
      "[830]\tvalid_0's l2: 0.145289\n",
      "[831]\tvalid_0's l2: 0.14527\n",
      "[832]\tvalid_0's l2: 0.145255\n",
      "[833]\tvalid_0's l2: 0.145225\n",
      "[834]\tvalid_0's l2: 0.145182\n",
      "[835]\tvalid_0's l2: 0.145195\n",
      "[836]\tvalid_0's l2: 0.145197\n",
      "[837]\tvalid_0's l2: 0.145258\n",
      "[838]\tvalid_0's l2: 0.145253\n",
      "[839]\tvalid_0's l2: 0.145254\n",
      "[840]\tvalid_0's l2: 0.145231\n",
      "[841]\tvalid_0's l2: 0.145216\n",
      "[842]\tvalid_0's l2: 0.145211\n",
      "[843]\tvalid_0's l2: 0.145217\n",
      "[844]\tvalid_0's l2: 0.145201\n",
      "[845]\tvalid_0's l2: 0.145183\n",
      "[846]\tvalid_0's l2: 0.145188\n",
      "[847]\tvalid_0's l2: 0.145189\n",
      "[848]\tvalid_0's l2: 0.145185\n",
      "[849]\tvalid_0's l2: 0.145182\n",
      "[850]\tvalid_0's l2: 0.14517\n",
      "[851]\tvalid_0's l2: 0.145152\n",
      "[852]\tvalid_0's l2: 0.145146\n",
      "[853]\tvalid_0's l2: 0.145137\n",
      "[854]\tvalid_0's l2: 0.145133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[855]\tvalid_0's l2: 0.145136\n",
      "[856]\tvalid_0's l2: 0.145135\n",
      "[857]\tvalid_0's l2: 0.145134\n",
      "[858]\tvalid_0's l2: 0.14513\n",
      "[859]\tvalid_0's l2: 0.145122\n",
      "[860]\tvalid_0's l2: 0.145132\n",
      "[861]\tvalid_0's l2: 0.145116\n",
      "[862]\tvalid_0's l2: 0.145128\n",
      "[863]\tvalid_0's l2: 0.145145\n",
      "[864]\tvalid_0's l2: 0.145144\n",
      "[865]\tvalid_0's l2: 0.145163\n",
      "[866]\tvalid_0's l2: 0.145153\n",
      "[867]\tvalid_0's l2: 0.14516\n",
      "[868]\tvalid_0's l2: 0.145149\n",
      "[869]\tvalid_0's l2: 0.145154\n",
      "[870]\tvalid_0's l2: 0.145123\n",
      "[871]\tvalid_0's l2: 0.145126\n",
      "[872]\tvalid_0's l2: 0.145121\n",
      "[873]\tvalid_0's l2: 0.145115\n",
      "[874]\tvalid_0's l2: 0.145115\n",
      "[875]\tvalid_0's l2: 0.145114\n",
      "[876]\tvalid_0's l2: 0.145115\n",
      "[877]\tvalid_0's l2: 0.145099\n",
      "[878]\tvalid_0's l2: 0.145101\n",
      "[879]\tvalid_0's l2: 0.145071\n",
      "[880]\tvalid_0's l2: 0.145087\n",
      "[881]\tvalid_0's l2: 0.145085\n",
      "[882]\tvalid_0's l2: 0.145071\n",
      "[883]\tvalid_0's l2: 0.14506\n",
      "[884]\tvalid_0's l2: 0.145064\n",
      "[885]\tvalid_0's l2: 0.145099\n",
      "[886]\tvalid_0's l2: 0.145058\n",
      "[887]\tvalid_0's l2: 0.145056\n",
      "[888]\tvalid_0's l2: 0.145054\n",
      "[889]\tvalid_0's l2: 0.145036\n",
      "[890]\tvalid_0's l2: 0.145049\n",
      "[891]\tvalid_0's l2: 0.145052\n",
      "[892]\tvalid_0's l2: 0.145043\n",
      "[893]\tvalid_0's l2: 0.14505\n",
      "[894]\tvalid_0's l2: 0.14502\n",
      "[895]\tvalid_0's l2: 0.145016\n",
      "[896]\tvalid_0's l2: 0.145011\n",
      "[897]\tvalid_0's l2: 0.144994\n",
      "[898]\tvalid_0's l2: 0.144985\n",
      "[899]\tvalid_0's l2: 0.14499\n",
      "[900]\tvalid_0's l2: 0.144988\n",
      "[901]\tvalid_0's l2: 0.144988\n",
      "[902]\tvalid_0's l2: 0.144973\n",
      "[903]\tvalid_0's l2: 0.144974\n",
      "[904]\tvalid_0's l2: 0.144985\n",
      "[905]\tvalid_0's l2: 0.144985\n",
      "[906]\tvalid_0's l2: 0.144973\n",
      "[907]\tvalid_0's l2: 0.144951\n",
      "[908]\tvalid_0's l2: 0.144945\n",
      "[909]\tvalid_0's l2: 0.144962\n",
      "[910]\tvalid_0's l2: 0.144935\n",
      "[911]\tvalid_0's l2: 0.144928\n",
      "[912]\tvalid_0's l2: 0.144931\n",
      "[913]\tvalid_0's l2: 0.144938\n",
      "[914]\tvalid_0's l2: 0.144935\n",
      "[915]\tvalid_0's l2: 0.144931\n",
      "[916]\tvalid_0's l2: 0.144956\n",
      "[917]\tvalid_0's l2: 0.144952\n",
      "[918]\tvalid_0's l2: 0.144962\n",
      "[919]\tvalid_0's l2: 0.144979\n",
      "[920]\tvalid_0's l2: 0.144976\n",
      "[921]\tvalid_0's l2: 0.144974\n",
      "[922]\tvalid_0's l2: 0.144954\n",
      "[923]\tvalid_0's l2: 0.144975\n",
      "[924]\tvalid_0's l2: 0.144965\n",
      "[925]\tvalid_0's l2: 0.144951\n",
      "[926]\tvalid_0's l2: 0.144946\n",
      "[927]\tvalid_0's l2: 0.14494\n",
      "[928]\tvalid_0's l2: 0.144931\n",
      "[929]\tvalid_0's l2: 0.144924\n",
      "[930]\tvalid_0's l2: 0.144921\n",
      "[931]\tvalid_0's l2: 0.144914\n",
      "[932]\tvalid_0's l2: 0.144921\n",
      "[933]\tvalid_0's l2: 0.144903\n",
      "[934]\tvalid_0's l2: 0.144902\n",
      "[935]\tvalid_0's l2: 0.144902\n",
      "[936]\tvalid_0's l2: 0.144926\n",
      "[937]\tvalid_0's l2: 0.144926\n",
      "[938]\tvalid_0's l2: 0.144936\n",
      "[939]\tvalid_0's l2: 0.144953\n",
      "[940]\tvalid_0's l2: 0.144959\n",
      "[941]\tvalid_0's l2: 0.144983\n",
      "[942]\tvalid_0's l2: 0.144976\n",
      "[943]\tvalid_0's l2: 0.14498\n",
      "[944]\tvalid_0's l2: 0.144964\n",
      "[945]\tvalid_0's l2: 0.144975\n",
      "[946]\tvalid_0's l2: 0.144969\n",
      "[947]\tvalid_0's l2: 0.144987\n",
      "[948]\tvalid_0's l2: 0.144983\n",
      "[949]\tvalid_0's l2: 0.144967\n",
      "[950]\tvalid_0's l2: 0.144953\n",
      "[951]\tvalid_0's l2: 0.144957\n",
      "[952]\tvalid_0's l2: 0.144958\n",
      "[953]\tvalid_0's l2: 0.14497\n",
      "[954]\tvalid_0's l2: 0.144982\n",
      "[955]\tvalid_0's l2: 0.14499\n",
      "[956]\tvalid_0's l2: 0.145005\n",
      "[957]\tvalid_0's l2: 0.144984\n",
      "[958]\tvalid_0's l2: 0.144972\n",
      "[959]\tvalid_0's l2: 0.14497\n",
      "[960]\tvalid_0's l2: 0.144979\n",
      "[961]\tvalid_0's l2: 0.144984\n",
      "[962]\tvalid_0's l2: 0.144996\n",
      "[963]\tvalid_0's l2: 0.144987\n",
      "[964]\tvalid_0's l2: 0.144977\n",
      "[965]\tvalid_0's l2: 0.144973\n",
      "Early stopping, best iteration is:\n",
      "[935]\tvalid_0's l2: 0.144902\n",
      "RMSE: 0.3807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_train = lgb.Dataset(Xtr, ytr)\n",
    "lgb_eval = lgb.Dataset(Xv, yv, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "        'task' : 'train',\n",
    "        'boosting_type' : 'gbdt',\n",
    "        'objective' : 'regression',\n",
    "        'metric' : {'l2'},\n",
    "        'num_leaves' : 100,\n",
    "        'max_depth' : 5,\n",
    "        'learning_rate' : 0.2,\n",
    "        'feature_fraction' : 0.8,\n",
    "        'bagging_fraction' : 0.8,\n",
    "        #'bagging_freq': 5,\n",
    "        'min_data_in_leaf' : 500,\n",
    "        #'max_bin': 200,\n",
    "        'verbose' : 0\n",
    "}\n",
    "\n",
    "gbm2 = lgb.train(params,\n",
    "            lgb_train,\n",
    "            num_boost_round=5000,\n",
    "            valid_sets=lgb_eval,\n",
    "            early_stopping_rounds=30)\n",
    "y_pred = gbm2.predict(Xv, num_iteration=gbm2.best_iteration)\n",
    "rmse = np.sqrt(mean_squared_error(yv, y_pred))\n",
    "print(\"RMSE: %.4f\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbm</th>\n",
       "      <th>gbm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.323821</td>\n",
       "      <td>7.334568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.922910</td>\n",
       "      <td>6.937566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.693614</td>\n",
       "      <td>5.634628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.178876</td>\n",
       "      <td>6.057216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.080499</td>\n",
       "      <td>6.059073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gbm      gbm2\n",
       "0  7.323821  7.334568\n",
       "1  6.922910  6.937566\n",
       "2  5.693614  5.634628\n",
       "3  6.178876  6.057216\n",
       "4  6.080499  6.059073"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yNN = model.predict(Xv)\n",
    "# newX=pd.DataFrame(yNN)\n",
    "# yRF = reg.predict(Xv)\n",
    "# newX=pd.DataFrame(yRF)\n",
    "\n",
    "yGB = gbm.predict(Xv, num_iteration=gbm.best_iteration)\n",
    "XX = pd.DataFrame(yGB)\n",
    "yGB2 = gbm2.predict(Xv, num_iteration=gbm2.best_iteration)\n",
    "XX2 = pd.DataFrame(yGB2)\n",
    "\n",
    "res = pd.concat([XX,XX2],axis=1)\n",
    "res.columns=['gbm','gbm2']\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.79795415  0.20064334]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "# rr = Lasso(alpha=0.0001,precompute=True,max_iter=1000,\n",
    "#              positive=True, random_state=9999, selection='random')\n",
    "rr = LinearRegression()\n",
    "rr.fit(res,yv)\n",
    "print(rr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RFy = reg.predict(test[feature_names].values)\n",
    "#GBy2 = gbm2.predict(test[feature_names].values)\n",
    "# print('Test shape OK.') if test.shape[0] == ytest.shape[0] else print('Oops')\n",
    "# #test['trip_duration'] = np.exp(ytest) - 1\n",
    "# #test[['id', 'trip_duration']].to_csv('double-d_submission.csv.gz', index=False, compression='gzip')\n",
    "#GBy = gbm.predict(test[feature_names].values)\n",
    "#test['trip_duration_rf'] = rr.coef_[0]*(np.exp(RFy) - 1)\n",
    "test['trip_duration_gb'] = rr.coef_[0]*(np.exp(GBy) - 1)\n",
    "test['trip_duration_gb2'] = rr.coef_[1]*(np.exp(GBy2) - 1)\n",
    "#test['trip_duration'] = np.max(test['trip_duration_rf']+test['trip_duration_gb'],0)\n",
    "test['trip_duration'] = test['trip_duration_gb2']+test['trip_duration_gb']\n",
    "#test['trip_duration'] = test['trip_duration_rf']+test['trip_duration_gb']\n",
    "#test['trip_duration'] = (np.exp(GBy) - 1)\n",
    "\n",
    "test[['id', 'trip_duration']].to_csv('double-d_gbmmeerg_submission.csv.gz', index=False, compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['trip_duration'].quantile(.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_y_cut = 0.5\n",
    "high_y_cut = 8\n",
    "y_is_above_cut = (train['log_trip_duration'] > high_y_cut)\n",
    "y_is_below_cut = (train['log_trip_duration']  < low_y_cut)\n",
    "y_is_within_cut = (~y_is_above_cut & ~y_is_below_cut)\n",
    "#model1 = rfr.fit(np.array(train.loc[y_is_within_cut,:].values), y.loc[y_is_within_cut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['log_trip_duration'].quantile(.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['trip_duration'].loc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filt = (test['trip_duration'] < 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['trip_duration'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(test.loc[filt,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['trip_duration'][217686]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['id', 'trip_duration']].to_csv('double-d_avr2_submission.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-64bd60823d82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NaN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'median'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mXtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda2\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\imputation.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'statistics_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             X = check_array(X, accept_sparse='csc', dtype=FLOAT_DTYPES,\n\u001b[1;32m--> 313\u001b[1;33m                             force_all_finite=False, copy=self.copy)\n\u001b[0m\u001b[0;32m    314\u001b[0m             \u001b[0mstatistics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatistics_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=1)\n",
    "Xtr = imp.fit_transform(Xtr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-25a1d0e683c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "np.where(np.isnan(np.array(Xv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.57285511,  6.24816425,  5.93532981, ...,  7.43228655,\n",
       "        7.62990355,  7.06491495])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
